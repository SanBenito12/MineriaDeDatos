#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
COMPARADOR DE TAMA√ëOS DE MUESTRA - AN√ÅLISIS DE IMPACTO
Compara el rendimiento de t√©cnicas ML con muestras de diferente tama√±o
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.svm import SVC, SVR
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.metrics import accuracy_score, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import time
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class ComparadorTama√±oMuestra:
    """Comparador optimizado para evaluar el impacto del tama√±o de muestra"""
    
    def __init__(self, archivo_datos):
        self.archivo_datos = archivo_datos
        self.datos_completos = None
        self.resultados_comparacion = defaultdict(dict)
        
    def cargar_datos(self):
        """Carga datos completos del proyecto"""
        try:
            self.datos_completos = pd.read_csv(self.archivo_datos)
            print(f"‚úÖ Datos cargados: {self.datos_completos.shape[0]:,} registros totales")
            return True
        except Exception as e:
            print(f"‚ùå Error cargando datos: {e}")
            return False
    
    def crear_categorias_poblacion(self, poblacion):
        """Crear categor√≠as balanceadas para clasificaci√≥n"""
        if poblacion <= 100:
            return 'Muy_Peque√±a'
        elif poblacion <= 500:
            return 'Peque√±a'
        elif poblacion <= 2000:
            return 'Mediana'
        elif poblacion <= 8000:
            return 'Grande'
        else:
            return 'Muy_Grande'
    
    def preparar_datasets(self, tama√±os_muestra):
        """Prepara m√∫ltiples datasets con diferentes tama√±os"""
        # Variables predictoras principales
        variables_predictoras = [
            'POBFEM', 'POBMAS', 'TOTHOG', 'VIVTOT', 'P_15YMAS', 
            'P_60YMAS', 'GRAPROES', 'PEA', 'POCUPADA'
        ]
        
        variables_disponibles = [v for v in variables_predictoras 
                               if v in self.datos_completos.columns]
        
        # Crear variable de clasificaci√≥n
        self.datos_completos['CATEGORIA_POB'] = self.datos_completos['POBTOT'].apply(
            self.crear_categorias_poblacion
        )
        
        # Limpiar datos
        datos_limpios = self.datos_completos[variables_disponibles + ['POBTOT', 'CATEGORIA_POB']].dropna()
        
        print(f"üìä Variables disponibles: {len(variables_disponibles)}")
        print(f"üßπ Datos limpios: {len(datos_limpios):,} registros")
        
        # Crear datasets para cada tama√±o
        datasets = {}
        
        for tama√±o in tama√±os_muestra:
            if tama√±o == 'completo':
                datos_muestra = datos_limpios.copy()
                tama√±o_real = len(datos_muestra)
            else:
                # Muestreo estratificado para mantener proporciones
                try:
                    datos_muestra, _ = train_test_split(
                        datos_limpios, 
                        test_size=1-tama√±o/len(datos_limpios),
                        stratify=datos_limpios['CATEGORIA_POB'],
                        random_state=42
                    )
                    tama√±o_real = len(datos_muestra)
                except:
                    # Si falla estratificado, usar muestreo simple
                    datos_muestra = datos_limpios.sample(n=min(tama√±o, len(datos_limpios)), 
                                                       random_state=42)
                    tama√±o_real = len(datos_muestra)
            
            # Preparar X, y para regresi√≥n y clasificaci√≥n
            X = datos_muestra[variables_disponibles]
            y_regresion = datos_muestra['POBTOT']
            y_clasificacion = datos_muestra['CATEGORIA_POB']
            
            datasets[tama√±o] = {
                'X': X,
                'y_regresion': y_regresion,
                'y_clasificacion': y_clasificacion,
                'tama√±o_real': tama√±o_real,
                'distribucion_clases': y_clasificacion.value_counts().to_dict()
            }
            
            print(f"üìù Dataset {tama√±o}: {tama√±o_real:,} registros")
        
        return datasets, variables_disponibles
    
    def definir_modelos(self):
        """Define modelos optimizados para comparaci√≥n"""
        modelos_clasificacion = {
            'RandomForest': RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42),
            'LogisticRegression': LogisticRegression(max_iter=500, random_state=42),
            'SVM': SVC(kernel='rbf', random_state=42, probability=True),
            'NeuralNetwork': MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=300, 
                                         random_state=42, alpha=0.01)
        }
        
        modelos_regresion = {
            'RandomForest': RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42),
            'LinearRegression': LinearRegression(),
            'SVR': SVR(kernel='rbf', C=100),
            'NeuralNetwork': MLPRegressor(hidden_layer_sizes=(20, 10), max_iter=300, 
                                        random_state=42, alpha=0.01)
        }
        
        return modelos_clasificacion, modelos_regresion
    
    def evaluar_modelo_completo(self, modelo, X, y, tipo='clasificacion', cv_folds=5):
        """Evaluaci√≥n robusta con validaci√≥n cruzada anidada"""
        try:
            # Escalado si es necesario
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # Codificaci√≥n para clasificaci√≥n si es necesario
            if tipo == 'clasificacion' and not isinstance(y.iloc[0], (int, float)):
                le = LabelEncoder()
                y_encoded = le.fit_transform(y)
            else:
                y_encoded = y
            
            # Validaci√≥n cruzada estratificada
            if tipo == 'clasificacion':
                cv = StratifiedKFold(n_splits=min(cv_folds, len(np.unique(y_encoded))), 
                                   shuffle=True, random_state=42)
                scoring = 'accuracy'
            else:
                from sklearn.model_selection import KFold
                cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)
                scoring = 'r2'
            
            # Realizar validaci√≥n cruzada
            inicio_tiempo = time.time()
            scores = cross_val_score(modelo, X_scaled, y_encoded, cv=cv, scoring=scoring)
            tiempo_total = time.time() - inicio_tiempo
            
            # Divisi√≥n para prueba final
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y_encoded, test_size=0.2, random_state=42,
                stratify=y_encoded if tipo == 'clasificacion' else None
            )
            
            # Entrenar y evaluar
            modelo.fit(X_train, y_train)
            y_pred = modelo.predict(X_test)
            
            if tipo == 'clasificacion':
                score_final = accuracy_score(y_test, y_pred)
            else:
                score_final = r2_score(y_test, y_pred)
            
            return {
                'cv_mean': scores.mean(),
                'cv_std': scores.std(),
                'score_final': score_final,
                'tiempo': tiempo_total,
                'num_samples': len(X),
                'exito': True
            }
            
        except Exception as e:
            print(f"      ‚ùå Error: {str(e)[:50]}...")
            return {'exito': False, 'error': str(e)}
    
    def ejecutar_comparacion_completa(self, tama√±os_muestra=[500, 1000, 2000, 5000, 'completo']):
        """Ejecuta comparaci√≥n completa entre diferentes tama√±os"""
        print("üî¨ INICIANDO COMPARACI√ìN COMPLETA DE TAMA√ëOS DE MUESTRA")
        print("="*60)
        
        # Preparar datasets
        datasets, variables = self.preparar_datasets(tama√±os_muestra)
        
        # Definir modelos
        modelos_cls, modelos_reg = self.definir_modelos()
        
        print(f"\nüß™ EVALUANDO {len(modelos_cls)} T√âCNICAS EN {len(datasets)} TAMA√ëOS")
        print("-"*60)
        
        # Evaluar clasificaci√≥n
        print("\nüìä EVALUANDO CLASIFICACI√ìN:")
        for tama√±o, dataset in datasets.items():
            print(f"\n   üìù Tama√±o: {dataset['tama√±o_real']:,} registros")
            
            for nombre_modelo, modelo in modelos_cls.items():
                print(f"      üîÑ {nombre_modelo}...")
                
                resultado = self.evaluar_modelo_completo(
                    modelo, dataset['X'], dataset['y_clasificacion'], 
                    tipo='clasificacion'
                )
                
                if resultado['exito']:
                    self.resultados_comparacion[tama√±o][f"{nombre_modelo}_cls"] = resultado
                    print(f"         ‚úÖ CV: {resultado['cv_mean']:.3f}¬±{resultado['cv_std']:.3f} | "
                          f"Final: {resultado['score_final']:.3f} | "
                          f"Tiempo: {resultado['tiempo']:.1f}s")
        
        # Evaluar regresi√≥n
        print("\nüìà EVALUANDO REGRESI√ìN:")
        for tama√±o, dataset in datasets.items():
            print(f"\n   üìù Tama√±o: {dataset['tama√±o_real']:,} registros")
            
            for nombre_modelo, modelo in modelos_reg.items():
                print(f"      üîÑ {nombre_modelo}...")
                
                resultado = self.evaluar_modelo_completo(
                    modelo, dataset['X'], dataset['y_regresion'], 
                    tipo='regresion'
                )
                
                if resultado['exito']:
                    self.resultados_comparacion[tama√±o][f"{nombre_modelo}_reg"] = resultado
                    print(f"         ‚úÖ CV: {resultado['cv_mean']:.3f}¬±{resultado['cv_std']:.3f} | "
                          f"Final: {resultado['score_final']:.3f} | "
                          f"Tiempo: {resultado['tiempo']:.1f}s")
        
        return self.resultados_comparacion
    
    def analizar_resultados(self):
        """An√°lisis completo de los resultados obtenidos"""
        print("\n" + "="*60)
        print("üìä AN√ÅLISIS DE RESULTADOS")
        print("="*60)
        
        # Crear tablas de comparaci√≥n
        tama√±os = list(self.resultados_comparacion.keys())
        t√©cnicas = set()
        for resultados_tama√±o in self.resultados_comparacion.values():
            t√©cnicas.update(resultados_tama√±o.keys())
        
        t√©cnicas = sorted(list(t√©cnicas))
        
        # An√°lisis por m√©trica
        metricas = ['cv_mean', 'cv_std', 'score_final', 'tiempo']
        
        for metrica in metricas:
            print(f"\nüìà {metrica.upper()}:")
            print("-" * 50)
            
            # Crear tabla
            tabla = []
            for t√©cnica in t√©cnicas:
                fila = [t√©cnica[:15]]  # Limitar nombre
                for tama√±o in tama√±os:
                    if tama√±o in self.resultados_comparacion:
                        if t√©cnica in self.resultados_comparacion[tama√±o]:
                            valor = self.resultados_comparacion[tama√±o][t√©cnica].get(metrica, 0)
                            if metrica == 'tiempo':
                                fila.append(f"{valor:.1f}s")
                            else:
                                fila.append(f"{valor:.3f}")
                        else:
                            fila.append("N/A")
                    else:
                        fila.append("N/A")
                tabla.append(fila)
            
            # Mostrar tabla
            header = ["T√©cnica"] + [str(t) for t in tama√±os]
            print(f"{'T√©cnica':<15} | " + " | ".join([f"{h:>8}" for h in tama√±os]))
            print("-" * (15 + 4 + len(tama√±os) * 11))
            
            for fila in tabla:
                print(f"{fila[0]:<15} | " + " | ".join([f"{v:>8}" for v in fila[1:]]))
    
    def crear_visualizaciones(self):
        """Crear visualizaciones comprehensivas"""
        try:
            # Preparar datos para visualizaci√≥n
            datos_viz = []
            for tama√±o, resultados in self.resultados_comparacion.items():
                for t√©cnica, metrics in resultados.items():
                    tama√±o_real = metrics.get('num_samples', 0)
                    datos_viz.append({
                        'tama√±o': tama√±o,
                        'tama√±o_real': tama√±o_real,
                        't√©cnica': t√©cnica,
                        'tipo': 'Clasificaci√≥n' if '_cls' in t√©cnica else 'Regresi√≥n',
                        'cv_mean': metrics.get('cv_mean', 0),
                        'cv_std': metrics.get('cv_std', 0),
                        'score_final': metrics.get('score_final', 0),
                        'tiempo': metrics.get('tiempo', 0)
                    })
            
            df_viz = pd.DataFrame(datos_viz)
            
            if df_viz.empty:
                print("‚ö†Ô∏è No hay datos para visualizar")
                return False
            
            # Crear figura con m√∫ltiples subplots
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('üî¨ IMPACTO DEL TAMA√ëO DE MUESTRA EN MACHINE LEARNING', 
                        fontsize=16, fontweight='bold')
            
            # Gr√°fico 1: Precisi√≥n vs Tama√±o (Clasificaci√≥n)
            df_cls = df_viz[df_viz['tipo'] == 'Clasificaci√≥n']
            if not df_cls.empty:
                for t√©cnica in df_cls['t√©cnica'].unique():
                    datos_t√©cnica = df_cls[df_cls['t√©cnica'] == t√©cnica]
                    axes[0,0].plot(datos_t√©cnica['tama√±o_real'], datos_t√©cnica['cv_mean'], 
                                  'o-', label=t√©cnica.replace('_cls', ''), linewidth=2, markersize=6)
                
                axes[0,0].set_title('üìä Precisi√≥n vs Tama√±o - Clasificaci√≥n', fontweight='bold')
                axes[0,0].set_xlabel('Tama√±o de Muestra')
                axes[0,0].set_ylabel('Precisi√≥n (CV)')
                axes[0,0].legend()
                axes[0,0].grid(True, alpha=0.3)
                axes[0,0].set_xscale('log')
            
            # Gr√°fico 2: R¬≤ vs Tama√±o (Regresi√≥n)
            df_reg = df_viz[df_viz['tipo'] == 'Regresi√≥n']
            if not df_reg.empty:
                for t√©cnica in df_reg['t√©cnica'].unique():
                    datos_t√©cnica = df_reg[df_reg['t√©cnica'] == t√©cnica]
                    axes[0,1].plot(datos_t√©cnica['tama√±o_real'], datos_t√©cnica['cv_mean'], 
                                  's-', label=t√©cnica.replace('_reg', ''), linewidth=2, markersize=6)
                
                axes[0,1].set_title('üìà R¬≤ vs Tama√±o - Regresi√≥n', fontweight='bold')
                axes[0,1].set_xlabel('Tama√±o de Muestra')
                axes[0,1].set_ylabel('R¬≤ Score (CV)')
                axes[0,1].legend()
                axes[0,1].grid(True, alpha=0.3)
                axes[0,1].set_xscale('log')
            
            # Gr√°fico 3: Tiempo de entrenamiento vs Tama√±o
            axes[0,2].scatter(df_viz['tama√±o_real'], df_viz['tiempo'], 
                            c=['blue' if 'cls' in t else 'red' for t in df_viz['t√©cnica']], 
                            alpha=0.6, s=50)
            axes[0,2].set_title('‚è±Ô∏è Tiempo vs Tama√±o', fontweight='bold')
            axes[0,2].set_xlabel('Tama√±o de Muestra')
            axes[0,2].set_ylabel('Tiempo (segundos)')
            axes[0,2].set_xscale('log')
            axes[0,2].set_yscale('log')
            axes[0,2].grid(True, alpha=0.3)
            
            # Gr√°fico 4: Heatmap de rendimiento
            pivot_data = df_viz.pivot_table(
                index='t√©cnica', 
                columns='tama√±o', 
                values='cv_mean', 
                aggfunc='mean'
            )
            
            if not pivot_data.empty:
                sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1,0])
                axes[1,0].set_title('üî• Heatmap Rendimiento', fontweight='bold')
                axes[1,0].set_xlabel('Tama√±o Muestra')
                axes[1,0].set_ylabel('T√©cnica')
            
            # Gr√°fico 5: Variabilidad (CV_std) vs Tama√±o
            for tipo, color in [('Clasificaci√≥n', 'blue'), ('Regresi√≥n', 'red')]:
                datos_tipo = df_viz[df_viz['tipo'] == tipo]
                axes[1,1].scatter(datos_tipo['tama√±o_real'], datos_tipo['cv_std'], 
                                c=color, label=tipo, alpha=0.6, s=50)
            
            axes[1,1].set_title('üìä Variabilidad vs Tama√±o', fontweight='bold')
            axes[1,1].set_xlabel('Tama√±o de Muestra')
            axes[1,1].set_ylabel('Desviaci√≥n Est√°ndar CV')
            axes[1,1].legend()
            axes[1,1].set_xscale('log')
            axes[1,1].grid(True, alpha=0.3)
            
            # Gr√°fico 6: Eficiencia (Score/Tiempo)
            df_viz['eficiencia'] = df_viz['cv_mean'] / (df_viz['tiempo'] + 0.1)  # +0.1 para evitar divisi√≥n por 0
            
            axes[1,2].scatter(df_viz['tama√±o_real'], df_viz['eficiencia'], 
                            c=['green' if 'cls' in t else 'orange' for t in df_viz['t√©cnica']], 
                            alpha=0.6, s=50)
            axes[1,2].set_title('‚ö° Eficiencia vs Tama√±o', fontweight='bold')
            axes[1,2].set_xlabel('Tama√±o de Muestra')
            axes[1,2].set_ylabel('Eficiencia (Score/Tiempo)')
            axes[1,2].set_xscale('log')
            axes[1,2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('comparacion_tama√±o_muestra.png', dpi=150, bbox_inches='tight')
            plt.show()
            
            print("üíæ Visualizaci√≥n guardada: comparacion_tama√±o_muestra.png")
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en visualizaciones: {e}")
            return False
    
    def generar_recomendaciones(self):
        """Genera recomendaciones basadas en los resultados"""
        print("\n" + "="*60)
        print("üí° RECOMENDACIONES BASADAS EN AN√ÅLISIS")
        print("="*60)
        
        # An√°lizar tendencias
        mejores_por_tama√±o = {}
        diferencias_rendimiento = {}
        
        for tama√±o, resultados in self.resultados_comparacion.items():
            scores = [r['cv_mean'] for r in resultados.values() if r.get('cv_mean')]
            if scores:
                mejores_por_tama√±o[tama√±o] = max(scores)
        
        # Calcular diferencias
        if 'completo' in mejores_por_tama√±o and 2000 in mejores_por_tama√±o:
            diferencia_2k = mejores_por_tama√±o['completo'] - mejores_por_tama√±o[2000]
            porcentaje_perdida = (diferencia_2k / mejores_por_tama√±o['completo']) * 100
            
            print(f"üìä IMPACTO DE USAR 2,000 VS DATASET COMPLETO:")
            print(f"   ‚Ä¢ Mejor score con dataset completo: {mejores_por_tama√±o['completo']:.3f}")
            print(f"   ‚Ä¢ Mejor score con 2,000 muestras: {mejores_por_tama√±o[2000]:.3f}")
            print(f"   ‚Ä¢ Diferencia absoluta: {diferencia_2k:.3f}")
            print(f"   ‚Ä¢ P√©rdida porcentual: {porcentaje_perdida:.1f}%")
            
            if abs(porcentaje_perdida) < 5:
                print(f"   ‚úÖ RECOMENDACI√ìN: P√©rdida m√≠nima (<5%), usar 2K es aceptable")
            elif abs(porcentaje_perdida) < 15:
                print(f"   ‚ö†Ô∏è RECOMENDACI√ìN: P√©rdida moderada (5-15%), considerar m√°s datos")
            else:
                print(f"   ‚ùå RECOMENDACI√ìN: P√©rdida significativa (>15%), usar dataset completo")
        
        print(f"\nüéØ ESTRATEGIA RECOMENDADA:")
        print(f"   1. üìà DESARROLLO: Usar 2,000-5,000 muestras para desarrollo r√°pido")
        print(f"   2. üî¨ VALIDACI√ìN: Usar dataset completo para validaci√≥n final")
        print(f"   3. üìä COMPARACI√ìN: Siempre reportar ambos resultados")
        print(f"   4. üé≤ MUESTREO: Usar muestreo estratificado para mantener distribuciones")
        print(f"   5. ‚öñÔ∏è TRADE-OFF: Balancear tiempo vs precisi√≥n seg√∫n objetivos")

def main():
    """Funci√≥n principal para ejecutar la comparaci√≥n"""
    print("üî¨ SISTEMA DE COMPARACI√ìN DE TAMA√ëOS DE MUESTRA")
    print("="*60)
    
    # Configurar archivo de datos
    archivo_datos = 'data/ceros_sin_columnasAB_limpio_weka.csv'
    
    # Crear comparador
    comparador = ComparadorTama√±oMuestra(archivo_datos)
    
    # Cargar datos
    if not comparador.cargar_datos():
        print("‚ùå No se pueden cargar los datos")
        return
    
    # Definir tama√±os a comparar
    tama√±os_prueba = [500, 1000, 2000, 5000, 'completo']
    
    print(f"\nüéØ COMPARANDO TAMA√ëOS: {tama√±os_prueba}")
    
    # Ejecutar comparaci√≥n
    resultados = comparador.ejecutar_comparacion_completa(tama√±os_prueba)
    
    # Analizar resultados
    comparador.analizar_resultados()
    
    # Crear visualizaciones
    comparador.crear_visualizaciones()
    
    # Generar recomendaciones
    comparador.generar_recomendaciones()
    
    print("\n‚úÖ COMPARACI√ìN COMPLETADA")
    print("üìä Revisa los gr√°ficos y recomendaciones para tomar decisiones informadas")

if __name__ == "__main__":
    main()