#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
REGRESI√ìN LINEAL - Versi√≥n Ultra Simple
Predice la poblaci√≥n total usando otras variables demogr√°ficas
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

def ejecutar_regresion():
    print("üîµ REGRESI√ìN LINEAL")
    print("="*30)
    print("üìù Objetivo: Predecir POBLACI√ìN TOTAL usando otras variables")
    print()
    
    # 1. CARGAR DATOS
    archivo = 'ceros_sin_columnasAB_limpio_weka.csv'
    try:
        datos = pd.read_csv(archivo)
        print(f"‚úÖ Datos cargados: {datos.shape[0]:,} filas")
    except:
        print(f"‚ùå No se encontr√≥ el archivo: {archivo}")
        return
    
    # 2. SELECCIONAR VARIABLES M√ÅS IMPORTANTES
    variables_predictoras = ['POBFEM', 'POBMAS', 'TOTHOG', 'VIVTOT']
    variables_disponibles = [v for v in variables_predictoras if v in datos.columns]
    
    if len(variables_disponibles) < 2:
        print("‚ùå No hay suficientes variables para el an√°lisis")
        return
    
    print(f"üìä Variables usadas: {', '.join(variables_disponibles)}")
    
    # 3. PREPARAR DATOS (eliminar filas vac√≠as)
    datos_limpios = datos[variables_disponibles + ['POBTOT']].dropna()
    X = datos_limpios[variables_disponibles]  # Variables predictoras
    y = datos_limpios['POBTOT']              # Variable a predecir
    
    print(f"üßπ Datos limpios: {len(datos_limpios):,} registros")
    
    # 4. DIVIDIR EN ENTRENAMIENTO Y PRUEBA
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # 5. ESCALAR DATOS (importante para Ridge y Lasso)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"üìà Entrenamiento: {len(X_train):,} | Prueba: {len(X_test):,}")
    print()
    
    # 6. ENTRENAR 3 MODELOS DIFERENTES
    modelos = {
        'Lineal Simple': LinearRegression(),
        'Ridge (L2)': Ridge(alpha=1.0),
        'Lasso (L1)': Lasso(alpha=1.0, max_iter=1000)
    }
    
    print("ü§ñ ENTRENANDO MODELOS...")
    resultados = {}
    
    for nombre, modelo in modelos.items():
        # Entrenar modelo
        modelo.fit(X_train_scaled, y_train)
        
        # Hacer predicciones
        y_pred = modelo.predict(X_test_scaled)
        
        # Calcular precisi√≥n (R¬≤)
        precision = r2_score(y_test, y_pred)
        
        resultados[nombre] = {
            'modelo': modelo,
            'precision': precision,
            'predicciones': y_pred
        }
        
        print(f"   {nombre:15} ‚Üí Precisi√≥n: {precision:.3f} ({precision*100:.1f}%)")
    
    # 7. ENCONTRAR EL MEJOR MODELO
    mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
    mejor_precision = resultados[mejor_nombre]['precision']
    
    print()
    print(f"üèÜ MEJOR MODELO: {mejor_nombre}")
    print(f"   Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)")
    
    # 8. GR√ÅFICO SIMPLE Y CLARO
    try:
        plt.figure(figsize=(10, 5))
        
        # Gr√°fico 1: Comparaci√≥n de modelos
        plt.subplot(1, 2, 1)
        nombres = list(resultados.keys())
        precisiones = [resultados[m]['precision'] for m in nombres]
        colores = ['lightblue', 'lightgreen', 'orange']
        
        barras = plt.bar(range(len(nombres)), precisiones, color=colores)
        plt.title('üìä Precisi√≥n por Modelo', fontsize=12, fontweight='bold')
        plt.ylabel('Precisi√≥n (R¬≤)')
        plt.xticks(range(len(nombres)), nombres, rotation=45, ha='right')
        plt.ylim(0, 1)
        
        # A√±adir valores en las barras
        for i, (barra, precision) in enumerate(zip(barras, precisiones)):
            plt.text(i, precision + 0.02, f'{precision:.3f}', 
                    ha='center', fontweight='bold')
        
        # Gr√°fico 2: Predicciones vs Realidad (mejor modelo)
        plt.subplot(1, 2, 2)
        mejor_pred = resultados[mejor_nombre]['predicciones']
        
        plt.scatter(y_test, mejor_pred, alpha=0.6, color='blue', s=20)
        
        # L√≠nea de predicci√≥n perfecta
        min_val = min(y_test.min(), mejor_pred.min())
        max_val = max(y_test.max(), mejor_pred.max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, 
                label='Predicci√≥n Perfecta')
        
        plt.xlabel('Poblaci√≥n Real')
        plt.ylabel('Poblaci√≥n Predicha')
        plt.title(f'üéØ {mejor_nombre}\nPredicciones vs Realidad', fontsize=12, fontweight='bold')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('regresion_resultados.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        print("üíæ Gr√°fico guardado: regresion_resultados.png")
        
    except Exception as e:
        print(f"‚ö†Ô∏è No se pudo crear el gr√°fico: {e}")
    
    # 9. EXPLICACI√ìN SIMPLE
    print()
    print("üìù EXPLICACI√ìN:")
    print(f"   ‚Ä¢ El modelo {mejor_nombre} es el m√°s preciso")
    print(f"   ‚Ä¢ Puede explicar el {mejor_precision*100:.1f}% de la variaci√≥n en poblaci√≥n")
    if mejor_precision > 0.8:
        print("   ‚Ä¢ ¬°Excelente precisi√≥n! üéâ")
    elif mejor_precision > 0.6:
        print("   ‚Ä¢ Buena precisi√≥n üëç")
    else:
        print("   ‚Ä¢ Precisi√≥n moderada, se puede mejorar üîß")
    
    print("‚úÖ REGRESI√ìN LINEAL COMPLETADA")

if __name__ == "__main__":
    ejecutar_regresion()