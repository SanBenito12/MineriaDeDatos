#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CLASIFICACI√ìN BASADA EN EJEMPLARES (K-NN)
Clasifica bas√°ndose en los vecinos m√°s cercanos
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.spatial.distance import cdist
import warnings
warnings.filterwarnings('ignore')

def crear_categorias_poblacion(poblacion):
    """Crear categor√≠as de poblaci√≥n para clasificaci√≥n"""
    if poblacion <= 1000:
        return 'Peque√±a'
    elif poblacion <= 5000:
        return 'Mediana'
    elif poblacion <= 20000:
        return 'Grande'
    else:
        return 'Muy Grande'

def encontrar_k_optimo(X_train, y_train, k_max=20):
    """Encuentra el mejor valor de K usando validaci√≥n cruzada"""
    k_values = range(1, min(k_max + 1, len(X_train) // 5))
    cv_scores = []
    
    for k in k_values:
        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')
        scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')
        cv_scores.append(scores.mean())
    
    mejor_k = k_values[np.argmax(cv_scores)]
    mejor_score = max(cv_scores)
    
    return mejor_k, mejor_score, list(k_values), cv_scores

def analizar_distancias(X_train, X_test, n_muestras=100):
    """Analiza la distribuci√≥n de distancias entre puntos"""
    # Tomar muestra para an√°lisis (computacionalmente costoso)
    if len(X_train) > n_muestras:
        indices = np.random.choice(len(X_train), n_muestras, replace=False)
        X_muestra = X_train[indices]
    else:
        X_muestra = X_train
    
    # Calcular distancias
    distancias = cdist(X_muestra, X_muestra, metric='euclidean')
    
    # Estad√≠sticas de distancias
    distancias_no_cero = distancias[distancias > 0]
    
    stats = {
        'promedio': np.mean(distancias_no_cero),
        'mediana': np.median(distancias_no_cero),
        'std': np.std(distancias_no_cero),
        'min': np.min(distancias_no_cero),
        'max': np.max(distancias_no_cero)
    }
    
    return stats, distancias_no_cero

def ejecutar_clasificacion_ejemplares():
    print("üë• CLASIFICACI√ìN BASADA EN EJEMPLARES (K-NN)")
    print("="*45)
    print("üìù Objetivo: Clasificar bas√°ndose en vecinos m√°s cercanos")
    print()
    
    # 1. CARGAR DATOS
    archivo = '/home/sedc/Proyectos/MineriaDeDatos/data/ceros_sin_columnasAB_limpio_weka.csv'
    try:
        datos = pd.read_csv(archivo)
        print(f"‚úÖ Datos cargados: {datos.shape[0]:,} filas, {datos.shape[1]} columnas")
    except Exception as e:
        print(f"‚ùå Error cargando datos: {e}")
        return
    
    # 2. SELECCIONAR VARIABLES PREDICTORAS
    variables_predictoras = [
        'POBFEM', 'POBMAS', 'TOTHOG', 'VIVTOT', 'P_15YMAS', 
        'P_60YMAS', 'GRAPROES', 'PEA', 'POCUPADA', 'PDESOCUP'
    ]
    
    variables_disponibles = [v for v in variables_predictoras if v in datos.columns]
    
    if len(variables_disponibles) < 3:
        print("‚ùå No hay suficientes variables para clasificaci√≥n")
        return
    
    print(f"üìä Variables usadas: {', '.join(variables_disponibles)}")
    
    # 3. CREAR VARIABLE OBJETIVO
    datos['CATEGORIA_POB'] = datos['POBTOT'].apply(crear_categorias_poblacion)
    
    # 4. PREPARAR DATOS
    datos_limpios = datos[variables_disponibles + ['CATEGORIA_POB']].dropna()
    
    # Reducir muestra si es muy grande (K-NN es costoso)
    if len(datos_limpios) > 5000:
        datos_limpios = datos_limpios.sample(n=5000, random_state=42)
        print(f"üìù Muestra reducida a {len(datos_limpios):,} registros (para eficiencia)")
    
    X = datos_limpios[variables_disponibles]
    y = datos_limpios['CATEGORIA_POB']
    
    print(f"üßπ Datos finales: {len(datos_limpios):,} registros")
    print(f"üìà Distribuci√≥n de categor√≠as:")
    for categoria, count in y.value_counts().items():
        print(f"   {categoria:12}: {count:,} ({count/len(y)*100:.1f}%)")
    
    # 5. DIVIDIR DATOS
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    # 6. ESCALAR DATOS (MUY IMPORTANTE PARA K-NN)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"üìä Entrenamiento: {len(X_train):,} | Prueba: {len(X_test):,}")
    print()
    
    # 7. ENCONTRAR EL MEJOR VALOR DE K
    print("üîç BUSCANDO EL MEJOR VALOR DE K...")
    mejor_k, mejor_cv_score, k_values, cv_scores = encontrar_k_optimo(X_train_scaled, y_train)
    
    print(f"   ‚úÖ Mejor K: {mejor_k}")
    print(f"   üìä Score CV: {mejor_cv_score:.3f} ({mejor_cv_score*100:.1f}%)")
    print()
    
    # 8. ENTRENAR DIFERENTES CONFIGURACIONES DE K-NN
    configuraciones = {
        f'K-NN √ìptimo (K={mejor_k})': {
            'n_neighbors': mejor_k,
            'weights': 'distance'
        },
        'K-NN Cl√°sico (K=5)': {
            'n_neighbors': 5,
            'weights': 'uniform'
        },
        'K-NN Ponderado (K=7)': {
            'n_neighbors': 7,
            'weights': 'distance'
        },
        'K-NN Conservative (K=15)': {
            'n_neighbors': min(15, len(X_train) // 10),
            'weights': 'distance'
        }
    }
    
    print("üë• ENTRENANDO MODELOS K-NN...")
    resultados = {}
    
    for nombre, params in configuraciones.items():
        print(f"   üîÑ Entrenando {nombre}...")
        
        try:
            # Crear y entrenar modelo
            modelo = KNeighborsClassifier(**params, metric='euclidean')
            modelo.fit(X_train_scaled, y_train)
            
            # Predicciones
            y_pred = modelo.predict(X_test_scaled)
            y_pred_proba = modelo.predict_proba(X_test_scaled)
            
            # M√©tricas
            precision = accuracy_score(y_test, y_pred)
            
            resultados[nombre] = {
                'modelo': modelo,
                'precision': precision,
                'predicciones': y_pred,
                'probabilidades': y_pred_proba,
                'k': params['n_neighbors'],
                'weights': params['weights']
            }
            
            print(f"   ‚úÖ {nombre} ‚Üí Precisi√≥n: {precision:.3f} ({precision*100:.1f}%)")
            
        except Exception as e:
            print(f"   ‚ùå Error en {nombre}: {e}")
    
    if not resultados:
        print("‚ùå No se pudo entrenar ning√∫n modelo K-NN")
        return
    
    # 9. ENCONTRAR EL MEJOR MODELO
    mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
    mejor_modelo = resultados[mejor_nombre]['modelo']
    mejor_precision = resultados[mejor_nombre]['precision']
    
    print()
    print(f"üèÜ MEJOR MODELO: {mejor_nombre}")
    print(f"   Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)")
    print(f"   K utilizado: {resultados[mejor_nombre]['k']}")
    print(f"   Ponderaci√≥n: {resultados[mejor_nombre]['weights']}")
    
    # 10. AN√ÅLISIS DETALLADO
    print()
    print("üìä AN√ÅLISIS DETALLADO:")
    y_pred_mejor = resultados[mejor_nombre]['predicciones']
    
    # Reporte por clase
    print("\nüéØ M√©tricas por Categor√≠a:")
    reporte = classification_report(y_test, y_pred_mejor, output_dict=True)
    for categoria in ['Peque√±a', 'Mediana', 'Grande', 'Muy Grande']:
        if categoria in reporte:
            precision = reporte[categoria]['precision']
            recall = reporte[categoria]['recall']
            f1 = reporte[categoria]['f1-score']
            support = reporte[categoria]['support']
            print(f"   {categoria:12}: Prec={precision:.3f} | Rec={recall:.3f} | F1={f1:.3f} | N={support}")
    
    # 11. AN√ÅLISIS DE DISTANCIAS
    print()
    print("üìè AN√ÅLISIS DE DISTANCIAS:")
    try:
        stats_dist, distancias = analizar_distancias(X_train_scaled, X_test_scaled)
        print(f"   üìä Distancia promedio: {stats_dist['promedio']:.3f}")
        print(f"   üìä Distancia mediana: {stats_dist['mediana']:.3f}")
        print(f"   üìä Desviaci√≥n est√°ndar: {stats_dist['std']:.3f}")
        print(f"   üìä Rango: [{stats_dist['min']:.3f}, {stats_dist['max']:.3f}]")
    except Exception as e:
        print(f"   ‚ö†Ô∏è Error calculando distancias: {e}")
        distancias = None
    
    # 12. AN√ÅLISIS DE VECINOS
    print()
    print("üë• AN√ÅLISIS DE VECINOS:")
    try:
        # Obtener distancias y √≠ndices de vecinos para algunas muestras
        if len(X_test_scaled) > 0:
            distancias_vecinos, indices_vecinos = mejor_modelo.kneighbors(X_test_scaled[:5])
            
            for i in range(min(3, len(distancias_vecinos))):
                print(f"\n   Muestra {i+1}:")
                print(f"   Clase real: {y_test.iloc[i]}")
                print(f"   Clase predicha: {y_pred_mejor[i]}")
                print(f"   Distancias a vecinos: {distancias_vecinos[i]}")
                
                # Clases de los vecinos
                clases_vecinos = y_train.iloc[indices_vecinos[i]].values
                print(f"   Clases de vecinos: {list(clases_vecinos)}")
    
    except Exception as e:
        print(f"   ‚ö†Ô∏è Error analizando vecinos: {e}")
    
    # 13. VISUALIZACIONES
    try:
        fig = plt.figure(figsize=(18, 12))
        
        # Gr√°fico 1: Evoluci√≥n de precisi√≥n con K
        plt.subplot(3, 4, 1)
        plt.plot(k_values, cv_scores, 'b-o', linewidth=2, markersize=6)
        plt.axvline(x=mejor_k, color='red', linestyle='--', label=f'Mejor K={mejor_k}')
        plt.title('üîç Precisi√≥n vs Valor de K', fontweight='bold')
        plt.xlabel('K (N√∫mero de Vecinos)')
        plt.ylabel('Precisi√≥n (CV)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Gr√°fico 2: Comparaci√≥n de modelos
        plt.subplot(3, 4, 2)
        nombres = list(resultados.keys())
        precisiones = [resultados[m]['precision'] for m in nombres]
        colores = ['lightblue', 'lightgreen', 'orange', 'pink']
        
        barras = plt.bar(range(len(nombres)), precisiones, color=colores[:len(nombres)])
        plt.title('üë• Precisi√≥n por Configuraci√≥n', fontweight='bold')
        plt.ylabel('Precisi√≥n')
        plt.xticks(range(len(nombres)), [n.split('(')[0] for n in nombres], rotation=45, ha='right')
        plt.ylim(0, 1)
        
        for i, (barra, precision) in enumerate(zip(barras, precisiones)):
            plt.text(i, precision + 0.02, f'{precision:.3f}', ha='center', fontweight='bold')
        
        # Gr√°fico 3: Matriz de confusi√≥n
        plt.subplot(3, 4, 3)
        cm = confusion_matrix(y_test, y_pred_mejor)
        clases = mejor_modelo.classes_
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=clases, yticklabels=clases)
        plt.title(f'üéØ Matriz de Confusi√≥n\n{mejor_nombre.split("(")[0]}', fontweight='bold')
        plt.xlabel('Predicci√≥n')
        plt.ylabel('Real')
        
        # Gr√°fico 4: Distribuci√≥n de distancias (si disponible)
        plt.subplot(3, 4, 4)
        if distancias is not None and len(distancias) > 0:
            plt.hist(distancias, bins=30, alpha=0.7, color='purple', edgecolor='black')
            plt.title('üìè Distribuci√≥n de Distancias', fontweight='bold')
            plt.xlabel('Distancia Euclidiana')
            plt.ylabel('Frecuencia')
        else:
            plt.text(0.5, 0.5, 'An√°lisis de distancias\nno disponible', 
                    ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('üìè Distribuci√≥n de Distancias', fontweight='bold')
        
        # Gr√°fico 5: F1-Score por categor√≠a
        plt.subplot(3, 4, 5)
        f1_scores = []
        categorias_f1 = []
        for categoria in ['Peque√±a', 'Mediana', 'Grande', 'Muy Grande']:
            if categoria in reporte:
                f1_scores.append(reporte[categoria]['f1-score'])
                categorias_f1.append(categoria)
        
        plt.bar(categorias_f1, f1_scores, color='gold')
        plt.title('üéØ F1-Score por Categor√≠a', fontweight='bold')
        plt.ylabel('F1-Score')
        plt.xticks(rotation=45)
        
        # Gr√°fico 6: Comparaci√≥n de K values utilizados
        plt.subplot(3, 4, 6)
        k_vals = [resultados[m]['k'] for m in nombres]
        weights = [resultados[m]['weights'] for m in nombres]
        
        colores_k = ['blue' if w == 'uniform' else 'red' for w in weights]
        plt.scatter(k_vals, precisiones, c=colores_k, s=100, alpha=0.7)
        for i, nombre in enumerate(nombres):
            plt.annotate(nombre.split('(')[0][:8], (k_vals[i], precisiones[i]), 
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        plt.xlabel('Valor de K')
        plt.ylabel('Precisi√≥n')
        plt.title('üìä K vs Precisi√≥n\nüîµUniform üî¥Distance', fontweight='bold')
        
        # Gr√°fico 7: Distribuci√≥n de confianza
        plt.subplot(3, 4, 7)
        probabilidades = resultados[mejor_nombre]['probabilidades']
        max_probs = np.max(probabilidades, axis=1)
        plt.hist(max_probs, bins=20, alpha=0.7, color='green', edgecolor='black')
        plt.title('üìà Confianza de Predicciones', fontweight='bold')
        plt.xlabel('Confianza M√°xima')
        plt.ylabel('Frecuencia')
        
        # Gr√°fico 8: Precisi√≥n por tama√±o de K
        plt.subplot(3, 4, 8)
        k_sizes = ['Peque√±o (1-5)', 'Mediano (6-10)', 'Grande (11-20)']
        precisions_by_size = [[], [], []]
        
        for i, k in enumerate(k_values):
            if k <= 5:
                precisions_by_size[0].append(cv_scores[i])
            elif k <= 10:
                precisions_by_size[1].append(cv_scores[i])
            else:
                precisions_by_size[2].append(cv_scores[i])
        
        avg_precisions = [np.mean(p) if p else 0 for p in precisions_by_size]
        plt.bar(k_sizes, avg_precisions, color=['lightcoral', 'lightblue', 'lightgreen'])
        plt.title('üìä Precisi√≥n por Tama√±o K', fontweight='bold')
        plt.ylabel('Precisi√≥n Promedio')
        plt.xticks(rotation=45)
        
        # Gr√°fico 9: Errores por categor√≠a
        plt.subplot(3, 4, 9)
        errores_por_categoria = {}
        for real, pred in zip(y_test, y_pred_mejor):
            if real != pred:
                errores_por_categoria[real] = errores_por_categoria.get(real, 0) + 1
        
        if errores_por_categoria:
            categorias_error = list(errores_por_categoria.keys())
            conteo_errores = list(errores_por_categoria.values())
            plt.bar(categorias_error, conteo_errores, color='red', alpha=0.7)
            plt.title('‚ùå Errores por Categor√≠a', fontweight='bold')
            plt.ylabel('N√∫mero de Errores')
            plt.xticks(rotation=45)
        
        # Gr√°fico 10: Support por categor√≠a
        plt.subplot(3, 4, 10)
        supports = []
        for categoria in categorias_f1:
            supports.append(reporte[categoria]['support'])
        
        plt.bar(categorias_f1, supports, color='cyan')
        plt.title('üìä Muestras por Categor√≠a', fontweight='bold')
        plt.ylabel('N√∫mero de Muestras')
        plt.xticks(rotation=45)
        
        # Gr√°fico 11: Evoluci√≥n de precisi√≥n (curva suavizada)
        plt.subplot(3, 4, 11)
        if len(cv_scores) > 5:
            from scipy.ndimage import gaussian_filter1d
            cv_scores_smooth = gaussian_filter1d(cv_scores, sigma=0.8)
            plt.plot(k_values, cv_scores, 'o-', alpha=0.5, label='Original')
            plt.plot(k_values, cv_scores_smooth, 'r-', linewidth=2, label='Suavizada')
            plt.axvline(x=mejor_k, color='green', linestyle='--', label=f'√ìptimo K={mejor_k}')
            plt.title('üìà Curva de Aprendizaje K-NN', fontweight='bold')
            plt.xlabel('K')
            plt.ylabel('Precisi√≥n CV')
            plt.legend()
        
        # Gr√°fico 12: Heatmap de confusi√≥n normalizada
        plt.subplot(3, 4, 12)
        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Reds',
                   xticklabels=clases, yticklabels=clases)
        plt.title('üî• Confusi√≥n Normalizada', fontweight='bold')
        plt.xlabel('Predicci√≥n')
        plt.ylabel('Real')
        
        plt.tight_layout()
        plt.savefig('/home/sedc/Proyectos/MineriaDeDatos/results/graficos/clasificacion_knn.png', 
                   dpi=150, bbox_inches='tight')
        plt.show()
        
        print("üíæ Gr√°ficos guardados en: results/graficos/clasificacion_knn.png")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error creando visualizaciones: {e}")
    
    # 14. GUARDAR RESULTADOS
    try:
        import joblib
        
        # Guardar el mejor modelo y el scaler
        joblib.dump(mejor_modelo, '/home/sedc/Proyectos/MineriaDeDatos/results/modelos/mejor_knn_clasificacion.pkl')
        joblib.dump(scaler, '/home/sedc/Proyectos/MineriaDeDatos/results/modelos/scaler_knn.pkl')
        
        # Crear reporte detallado
        reporte_completo = f"""
REPORTE CLASIFICACI√ìN K-NN (BASADA EN EJEMPLARES)
===============================================

MEJOR MODELO: {mejor_nombre}
Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)
K √ìptimo: {mejor_k}
Valor K usado: {resultados[mejor_nombre]['k']}
Ponderaci√≥n: {resultados[mejor_nombre]['weights']}

B√öSQUEDA DE K √ìPTIMO:
- Rango evaluado: {min(k_values)} - {max(k_values)}
- Mejor score CV: {mejor_cv_score:.3f}

COMPARACI√ìN DE CONFIGURACIONES:
"""
        for nombre, resultado in resultados.items():
            reporte_completo += f"\n{nombre}:"
            reporte_completo += f"\n  - Precisi√≥n: {resultado['precision']:.3f}"
            reporte_completo += f"\n  - K: {resultado['k']}"
            reporte_completo += f"\n  - Weights: {resultado['weights']}"
        
        if 'stats_dist' in locals():
            reporte_completo += f"""

AN√ÅLISIS DE DISTANCIAS:
- Distancia promedio: {stats_dist['promedio']:.3f}
- Distancia mediana: {stats_dist['mediana']:.3f}
- Desviaci√≥n est√°ndar: {stats_dist['std']:.3f}
- Rango: [{stats_dist['min']:.3f}, {stats_dist['max']:.3f}]
"""
        
        reporte_completo += f"""

VARIABLES UTILIZADAS:
{', '.join(variables_disponibles)}

DATOS:
- Total registros: {len(datos_limpios):,}
- Variables predictoras: {len(variables_disponibles)}
- Categor√≠as: {len(clases)}
- Entrenamiento: {len(X_train):,}
- Prueba: {len(X_test):,}

NOTAS:
- Los datos fueron escalados usando StandardScaler
- Se utiliz√≥ distancia Euclidiana
- Se aplic√≥ validaci√≥n cruzada para encontrar K √≥ptimo
"""
        
        with open('/home/sedc/Proyectos/MineriaDeDatos/results/reportes/clasificacion_knn_reporte.txt', 'w', encoding='utf-8') as f:
            f.write(reporte_completo)
        
        print("üíæ Modelo guardado en: results/modelos/mejor_knn_clasificacion.pkl")
        print("üíæ Scaler guardado en: results/modelos/scaler_knn.pkl")
        print("üìÑ Reporte guardado en: results/reportes/clasificacion_knn_reporte.txt")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error guardando archivos: {e}")
    
    # 15. RESUMEN FINAL
    print()
    print("üìù RESUMEN K-NN (BASADO EN EJEMPLARES):")
    print(f"   ‚Ä¢ Mejor configuraci√≥n: K={resultados[mejor_nombre]['k']}, weights={resultados[mejor_nombre]['weights']}")
    print(f"   ‚Ä¢ Precisi√≥n alcanzada: {mejor_precision*100:.1f}%")
    print(f"   ‚Ä¢ K √≥ptimo encontrado: {mejor_k}")
    
    if mejor_precision > 0.8:
        print("   ‚Ä¢ ¬°Excelente clasificaci√≥n por similitud! üéâ")
    elif mejor_precision > 0.6:
        print("   ‚Ä¢ Buena clasificaci√≥n basada en vecinos üëç")
    else:
        print("   ‚Ä¢ Clasificaci√≥n moderada, considerar m√°s datos üîß")
    
    print("   ‚Ä¢ Ventaja: No requiere entrenamiento, se adapta a nuevos datos")
    print("   ‚Ä¢ Desventaja: Computacionalmente costoso para predicci√≥n")
    
    print("‚úÖ CLASIFICACI√ìN BASADA EN EJEMPLARES COMPLETADA")
    return resultados

if __name__ == "__main__":
    ejecutar_clasificacion_ejemplares()