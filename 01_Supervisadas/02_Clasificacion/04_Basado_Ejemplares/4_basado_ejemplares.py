#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CLASIFICACI√ìN BASADA EN EJEMPLARES (K-NN) - Versi√≥n Optimizada
Clasificaci√≥n por similitud con vecinos cercanos
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

def crear_categorias_poblacion_dinamica(datos):
    """Crear categor√≠as balanceadas basadas en cuartiles"""
    q1 = datos['POBTOT'].quantile(0.25)
    q2 = datos['POBTOT'].quantile(0.50)
    q3 = datos['POBTOT'].quantile(0.75)
    
    def categorizar(poblacion):
        if poblacion <= q1:
            return 'Peque√±a'
        elif poblacion <= q2:
            return 'Mediana'
        elif poblacion <= q3:
            return 'Grande'
        else:
            return 'Muy_Grande'
    
    return categorizar

def preparar_datos_knn(datos):
    """Prepara datos espec√≠ficamente para K-NN"""
    variables_predictoras = [
        'POBFEM', 'POBMAS', 'TOTHOG', 'VIVTOT', 'P_15YMAS', 
        'P_60YMAS', 'GRAPROES', 'PEA', 'POCUPADA'
    ]
    
    variables_disponibles = [v for v in variables_predictoras if v in datos.columns]
    
    if len(variables_disponibles) < 5:
        return None, None, None
    
    # Crear categor√≠as din√°micas
    categorizador = crear_categorias_poblacion_dinamica(datos)
    datos['CATEGORIA_POB'] = datos['POBTOT'].apply(categorizador)
    
    # Limpiar datos
    datos_limpios = datos[variables_disponibles + ['CATEGORIA_POB']].dropna()
    
    # Reducir muestra para eficiencia (K-NN es costoso)
    if len(datos_limpios) > 20000:
        try:
            datos_limpios = datos_limpios.groupby('CATEGORIA_POB').apply(
                lambda x: x.sample(min(len(x), 10000), random_state=42)
            ).reset_index(drop=True)
        except:
            datos_limpios = datos_limpios.sample(n=20000, random_state=42)
    
    X = datos_limpios[variables_disponibles]
    y = datos_limpios['CATEGORIA_POB']
    
    return X, y, variables_disponibles

def encontrar_k_optimo(X_train, y_train, k_max=15):
    """Encuentra el mejor valor de K usando validaci√≥n cruzada"""
    k_values = range(1, min(k_max + 1, len(X_train) // 5))
    cv_scores = []
    
    for k in k_values:
        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')
        scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')
        cv_scores.append(scores.mean())
    
    mejor_k = k_values[np.argmax(cv_scores)]
    mejor_score = max(cv_scores)
    
    return mejor_k, mejor_score, list(k_values), cv_scores

def entrenar_modelos_knn(X_train, X_test, y_train, y_test, mejor_k):
    """Entrena diferentes configuraciones de K-NN"""
    
    # Escalar datos (CR√çTICO para K-NN)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    configuraciones = {
        f'K-NN √ìptimo (K={mejor_k})': {
            'n_neighbors': mejor_k,
            'weights': 'distance'
        },
        'K-NN Cl√°sico (K=5)': {
            'n_neighbors': 5,
            'weights': 'uniform'
        },
        'K-NN Ponderado (K=7)': {
            'n_neighbors': 7,
            'weights': 'distance'
        }
    }
    
    resultados = {}
    
    for nombre, params in configuraciones.items():
        try:
            # Crear y entrenar modelo
            modelo = KNeighborsClassifier(**params, metric='euclidean')
            modelo.fit(X_train_scaled, y_train)
            
            # Predicciones
            y_pred = modelo.predict(X_test_scaled)
            y_pred_proba = modelo.predict_proba(X_test_scaled)
            
            # M√©tricas
            precision = accuracy_score(y_test, y_pred)
            
            resultados[nombre] = {
                'modelo': modelo,
                'precision': precision,
                'predicciones': y_pred,
                'probabilidades': y_pred_proba,
                'k': params['n_neighbors'],
                'weights': params['weights']
            }
            
        except Exception as e:
            continue
    
    return resultados, scaler

def crear_visualizaciones_knn(resultados, y_test, k_values, cv_scores, mejor_k):
    """Crear visualizaciones esenciales para K-NN"""
    try:
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('üë• CLASIFICACI√ìN K-NN - AN√ÅLISIS', fontsize=14, fontweight='bold')
        
        # Gr√°fico 1: Evoluci√≥n de precisi√≥n con K
        axes[0,0].plot(k_values, cv_scores, 'b-o', linewidth=2, markersize=6)
        axes[0,0].axvline(x=mejor_k, color='red', linestyle='--', label=f'Mejor K={mejor_k}')
        axes[0,0].set_title('üîç Precisi√≥n vs Valor de K', fontweight='bold')
        axes[0,0].set_xlabel('K (N√∫mero de Vecinos)')
        axes[0,0].set_ylabel('Precisi√≥n (CV)')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3)
        
        # Gr√°fico 2: Comparaci√≥n de configuraciones
        nombres = list(resultados.keys())
        precisiones = [resultados[m]['precision'] for m in nombres]
        colores = ['lightblue', 'lightgreen', 'orange']
        
        axes[0,1].bar(range(len(nombres)), precisiones, color=colores[:len(nombres)])
        axes[0,1].set_title('üë• Precisi√≥n por Configuraci√≥n', fontweight='bold')
        axes[0,1].set_ylabel('Precisi√≥n')
        axes[0,1].set_xticks(range(len(nombres)))
        axes[0,1].set_xticklabels([n.split('(')[0].strip() for n in nombres], rotation=45, ha='right')
        axes[0,1].set_ylim(0, 1)
        
        # A√±adir valores en las barras
        for i, precision in enumerate(precisiones):
            axes[0,1].text(i, precision + 0.02, f'{precision:.3f}', ha='center', fontweight='bold')
        
        # Gr√°fico 3: Matriz de confusi√≥n del mejor modelo
        mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
        y_pred_mejor = resultados[mejor_nombre]['predicciones']
        clases = resultados[mejor_nombre]['modelo'].classes_
        
        cm = confusion_matrix(y_test, y_pred_mejor)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=clases, yticklabels=clases, ax=axes[1,0])
        axes[1,0].set_title(f'üéØ Matriz de Confusi√≥n\n{mejor_nombre.split("(")[0].strip()}', fontweight='bold')
        axes[1,0].set_xlabel('Predicci√≥n')
        axes[1,0].set_ylabel('Real')
        
        # Gr√°fico 4: Distribuci√≥n de confianza
        probabilidades = resultados[mejor_nombre]['probabilidades']
        max_probs = np.max(probabilidades, axis=1)
        
        axes[1,1].hist(max_probs, bins=20, alpha=0.7, color='green', edgecolor='black')
        axes[1,1].set_title('üìà Distribuci√≥n de Confianza', fontweight='bold')
        axes[1,1].set_xlabel('Confianza M√°xima')
        axes[1,1].set_ylabel('Frecuencia')
        
        plt.tight_layout()
        plt.savefig('/home/sedc/Proyectos/MineriaDeDatos/results/graficos/clasificacion_knn.png', 
                   dpi=150, bbox_inches='tight')
        plt.show()
        
        return True
        
    except Exception as e:
        return False

def analizar_vecinos_cercanos(modelo, X_test_scaled, y_test, y_pred, n_ejemplos=3):
    """Analiza los vecinos m√°s cercanos para algunos ejemplos"""
    print(f"\nüë• AN√ÅLISIS DE VECINOS:")
    
    try:
        # Obtener distancias y √≠ndices de vecinos
        distancias, indices = modelo.kneighbors(X_test_scaled[:n_ejemplos])
        
        for i in range(n_ejemplos):
            print(f"   Ejemplo {i+1}: Real={y_test.iloc[i]} | Predicho={y_pred[i]}")
            print(f"      Distancias: {distancias[i]}")
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è Error: {e}")

def guardar_resultados_knn(resultados, variables_disponibles, mejor_k, datos_info):
    """Guardar modelo y reporte de manera optimizada"""
    try:
        import joblib
        
        # Mejor modelo
        mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
        mejor_modelo = resultados[mejor_nombre]['modelo']
        mejor_precision = resultados[mejor_nombre]['precision']
        
        # Guardar modelo
        joblib.dump(mejor_modelo, '/home/sedc/Proyectos/MineriaDeDatos/results/modelos/mejor_knn_clasificacion.pkl')
        
        # Crear reporte conciso
        reporte = f"""
REPORTE CLASIFICACI√ìN K-NN (BASADA EN EJEMPLARES)
===============================================

MEJOR MODELO: {mejor_nombre}
Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)
K √ìptimo encontrado: {mejor_k}
K utilizado: {resultados[mejor_nombre]['k']}
Ponderaci√≥n: {resultados[mejor_nombre]['weights']}

COMPARACI√ìN DE CONFIGURACIONES:
"""
        for nombre, resultado in resultados.items():
            reporte += f"\n{nombre}:"
            reporte += f"\n  - Precisi√≥n: {resultado['precision']:.3f}"
            reporte += f"\n  - K: {resultado['k']}"
            reporte += f"\n  - Weights: {resultado['weights']}"
        
        reporte += f"""

DATOS PROCESADOS:
- Registros: {datos_info['n_registros']:,}
- Variables: {len(variables_disponibles)}
- Entrenamiento: {datos_info['n_train']:,}
- Prueba: {datos_info['n_test']:,}

VARIABLES UTILIZADAS:
{', '.join(variables_disponibles)}

PRINCIPIO K-NN:
- Clasifica seg√∫n la mayor√≠a de los K vecinos m√°s cercanos
- No requiere entrenamiento (lazy learning)
- Sensible a la escala (por eso se aplica StandardScaler)
- Computacionalmente costoso para predicci√≥n

CONFIGURACI√ìN:
- M√©trica de distancia: Euclidiana
- Escalado aplicado: StandardScaler
- Validaci√≥n cruzada: 5-fold para K √≥ptimo
"""
        
        with open('/home/sedc/Proyectos/MineriaDeDatos/results/reportes/clasificacion_knn_reporte.txt', 'w', encoding='utf-8') as f:
            f.write(reporte)
        
        return True
        
    except Exception as e:
        return False

def ejecutar_clasificacion_ejemplares():
    """FUNCI√ìN PRINCIPAL - Mantiene compatibilidad con men√∫"""
    print("üë• CLASIFICACI√ìN BASADA EN EJEMPLARES (K-NN)")
    print("="*45)
    
    # 1. CARGAR DATOS
    archivo = '/home/sedc/Proyectos/MineriaDeDatos/data/ceros_sin_columnasAB_limpio_weka.csv'
    try:
        datos = pd.read_csv(archivo)
        print(f"‚úÖ Datos cargados: {datos.shape[0]:,} registros")
    except Exception as e:
        print(f"‚ùå Error cargando datos: {e}")
        return
    
    # 2. PREPARAR VARIABLES
    X, y, variables_disponibles = preparar_datos_knn(datos)
    if X is None:
        print("‚ùå No hay suficientes variables para K-NN")
        return
    
    print(f"üìä Variables: {len(variables_disponibles)} | Datos limpios: {len(X):,}")
    
    # Mostrar distribuci√≥n de categor√≠as
    distribucion = y.value_counts()
    print("üìà Categor√≠as:")
    for categoria, count in distribucion.items():
        print(f"   {categoria}: {count:,} ({count/len(y)*100:.1f}%)")
    
    # 3. DIVIDIR DATOS
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        print(f"üìä Divisi√≥n estratificada: {len(X_train):,} entrenamiento | {len(X_test):,} prueba")
    except ValueError:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        print(f"üìä Divisi√≥n simple: {len(X_train):,} entrenamiento | {len(X_test):,} prueba")
    
    print()
    
    # 4. ENCONTRAR K √ìPTIMO
    print("üîç Buscando K √≥ptimo...")
    mejor_k, mejor_cv_score, k_values, cv_scores = encontrar_k_optimo(X_train, y_train)
    print(f"   ‚úÖ Mejor K: {mejor_k} (CV Score: {mejor_cv_score:.3f})")
    
    # 5. ENTRENAR MODELOS K-NN
    print("\nüë• Entrenando modelos K-NN...")
    resultados, scaler = entrenar_modelos_knn(X_train, X_test, y_train, y_test, mejor_k)
    
    if not resultados:
        print("‚ùå No se pudieron entrenar modelos K-NN")
        return
    
    # Mostrar resultados
    for nombre, resultado in resultados.items():
        print(f"   {nombre:20} ‚Üí Precisi√≥n: {resultado['precision']:.3f} ({resultado['precision']*100:.1f}%)")
    
    # 6. ENCONTRAR MEJOR MODELO
    mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
    mejor_precision = resultados[mejor_nombre]['precision']
    
    print()
    print(f"üèÜ MEJOR MODELO: {mejor_nombre}")
    print(f"   Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)")
    print(f"   K utilizado: {resultados[mejor_nombre]['k']}")
    print(f"   Ponderaci√≥n: {resultados[mejor_nombre]['weights']}")
    
    # 7. AN√ÅLISIS DETALLADO
    y_pred_mejor = resultados[mejor_nombre]['predicciones']
    reporte = classification_report(y_test, y_pred_mejor, output_dict=True)
    
    print("\nüéØ M√©tricas por categor√≠a:")
    for categoria in y.unique():
        if categoria in reporte:
            precision = reporte[categoria]['precision']
            recall = reporte[categoria]['recall']
            f1 = reporte[categoria]['f1-score']
            print(f"   {categoria:12}: Prec={precision:.3f} | Rec={recall:.3f} | F1={f1:.3f}")
    
    # 8. AN√ÅLISIS DE VECINOS
    X_test_scaled = scaler.transform(X_test)
    analizar_vecinos_cercanos(resultados[mejor_nombre]['modelo'], X_test_scaled, 
                             y_test, y_pred_mejor)
    
    # 9. VISUALIZACIONES
    crear_visualizaciones_knn(resultados, y_test, k_values, cv_scores, mejor_k)
    
    # 10. GUARDAR RESULTADOS
    datos_info = {
        'n_registros': len(X),
        'n_train': len(X_train),
        'n_test': len(X_test)
    }
    
    guardar_resultados_knn(resultados, variables_disponibles, mejor_k, datos_info)
    
    # 11. RESUMEN FINAL
    print()
    print("üìù RESUMEN:")
    print(f"   ‚Ä¢ Configuraci√≥n: {mejor_nombre}")
    print(f"   ‚Ä¢ Precisi√≥n: {mejor_precision*100:.1f}%")
    print(f"   ‚Ä¢ K √≥ptimo: {mejor_k}")
    print(f"   ‚Ä¢ Variables: {len(variables_disponibles)}")
    
    if mejor_precision > 0.8:
        print("   üéâ ¬°Excelente clasificaci√≥n por similitud!")
    elif mejor_precision > 0.6:
        print("   üëç Buena clasificaci√≥n basada en vecinos")
    else:
        print("   üîß Clasificaci√≥n moderada")
    
    print("‚úÖ CLASIFICACI√ìN BASADA EN EJEMPLARES COMPLETADA")
    return resultados

if __name__ == "__main__":
    ejecutar_clasificacion_ejemplares()