#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
REDES NEURONALES - CLASIFICACI√ìN (Versi√≥n Optimizada)
Redes neuronales artificiales para clasificar poblaciones
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

def crear_categorias_poblacion_dinamica(datos):
    """Crear categor√≠as balanceadas basadas en cuartiles"""
    q1 = datos['POBTOT'].quantile(0.25)
    q2 = datos['POBTOT'].quantile(0.50)
    q3 = datos['POBTOT'].quantile(0.75)
    
    def categorizar(poblacion):
        if poblacion <= q1:
            return 'Peque√±a'
        elif poblacion <= q2:
            return 'Mediana'
        elif poblacion <= q3:
            return 'Grande'
        else:
            return 'Muy_Grande'
    
    return categorizar

def preparar_datos_redes(datos):
    """Prepara datos espec√≠ficamente para redes neuronales"""
    variables_predictoras = [
        'POBFEM', 'POBMAS', 'TOTHOG', 'VIVTOT', 'P_15YMAS', 
        'P_60YMAS', 'GRAPROES', 'PEA', 'POCUPADA'
    ]
    
    variables_disponibles = [v for v in variables_predictoras if v in datos.columns]
    
    if len(variables_disponibles) < 5:
        return None, None, None
    
    # Crear categor√≠as din√°micas
    categorizador = crear_categorias_poblacion_dinamica(datos)
    datos['CATEGORIA_POB'] = datos['POBTOT'].apply(categorizador)
    
    # Limpiar datos
    datos_limpios = datos[variables_disponibles + ['CATEGORIA_POB']].dropna()
    
    # Muestreo estratificado para balancear clases
    if len(datos_limpios) > 5000:
        try:
            datos_limpios = datos_limpios.groupby('CATEGORIA_POB').apply(
                lambda x: x.sample(min(len(x), 1250), random_state=42)
            ).reset_index(drop=True)
        except:
            datos_limpios = datos_limpios.sample(n=5000, random_state=42)
    
    # Convertir variables a tipo num√©rico
    for var in variables_disponibles:
        datos_limpios[var] = pd.to_numeric(datos_limpios[var], errors='coerce')
    
    # Eliminar filas con NaN despu√©s de conversi√≥n
    datos_limpios = datos_limpios.dropna()
    
    X = datos_limpios[variables_disponibles]
    y = datos_limpios['CATEGORIA_POB']
    
    return X, y, variables_disponibles

def crear_arquitecturas_redes():
    """Define diferentes arquitecturas de redes neuronales optimizadas"""
    return {
        'Red Simple': {
            'hidden_layer_sizes': (20,),
            'activation': 'relu',
            'solver': 'lbfgs',
            'alpha': 0.01,
            'max_iter': 500,
            'descripcion': 'Una capa oculta con 20 neuronas'
        },
        'Red Profunda': {
            'hidden_layer_sizes': (30, 15),
            'activation': 'relu',
            'solver': 'lbfgs',
            'alpha': 0.01,
            'max_iter': 600,
            'descripcion': 'Dos capas: 30 y 15 neuronas'
        },
        'Red Tanh': {
            'hidden_layer_sizes': (25,),
            'activation': 'tanh',
            'solver': 'lbfgs',
            'alpha': 0.1,
            'max_iter': 400,
            'descripcion': 'Activaci√≥n tangente hiperb√≥lica'
        }
    }

def calcular_parametros_red(modelo, n_entrada):
    """Calcula n√∫mero aproximado de par√°metros en la red"""
    try:
        capas = modelo.hidden_layer_sizes
        if isinstance(capas, int):
            capas = (capas,)
        
        n_salida = len(modelo.classes_)
        
        # Calcular par√°metros
        n_parametros = n_entrada * capas[0]  # Primera capa
        for i in range(len(capas) - 1):
            n_parametros += capas[i] * capas[i + 1]  # Capas ocultas
        n_parametros += capas[-1] * n_salida  # Capa de salida
        n_parametros += sum(capas) + n_salida  # Bias
        
        return n_parametros
    except:
        return 0

def entrenar_redes_neuronales(X_train, X_test, y_train, y_test):
    """Entrena diferentes arquitecturas de redes neuronales"""
    
    # Escalar datos (CR√çTICO para redes neuronales)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    arquitecturas = crear_arquitecturas_redes()
    resultados = {}
    
    for nombre, config in arquitecturas.items():
        try:
            # Crear configuraci√≥n sin descripci√≥n
            config_modelo = {k: v for k, v in config.items() if k != 'descripcion'}
            config_modelo['random_state'] = 42
            
            # Crear y entrenar modelo
            modelo = MLPClassifier(**config_modelo)
            modelo.fit(X_train_scaled, y_train)
            
            # Predicciones
            y_pred = modelo.predict(X_test_scaled)
            y_pred_proba = modelo.predict_proba(X_test_scaled)
            
            # Calcular n√∫mero de par√°metros
            n_parametros = calcular_parametros_red(modelo, X_train_scaled.shape[1])
            
            # An√°lisis de convergencia
            convergencia = {
                'convergio': modelo.n_iter_ < modelo.max_iter,
                'iteraciones': modelo.n_iter_,
                'loss_curve': getattr(modelo, 'loss_curve_', None)
            }
            
            # M√©tricas
            precision = accuracy_score(y_test, y_pred)
            
            resultados[nombre] = {
                'modelo': modelo,
                'precision': precision,
                'predicciones': y_pred,
                'probabilidades': y_pred_proba,
                'arquitectura': config['hidden_layer_sizes'],
                'activacion': config['activation'],
                'descripcion': config['descripcion'],
                'n_parametros': n_parametros,
                'convergencia': convergencia
            }
            
        except Exception as e:
            continue
    
    return resultados, scaler

def crear_visualizaciones_redes(resultados, y_test, variables_disponibles):
    """Crear visualizaciones esenciales para redes neuronales"""
    try:
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        fig.suptitle('üß† REDES NEURONALES - AN√ÅLISIS', fontsize=14, fontweight='bold')
        
        # Gr√°fico 1: Comparaci√≥n de precisi√≥n por arquitectura
        nombres = list(resultados.keys())
        precisiones = [resultados[m]['precision'] for m in nombres]
        
        axes[0].bar(nombres, precisiones, color=['lightblue', 'lightgreen', 'orange'])
        axes[0].set_title('üß† Precisi√≥n por Arquitectura', fontweight='bold')
        axes[0].set_ylabel('Precisi√≥n')
        axes[0].tick_params(axis='x', rotation=45)
        axes[0].set_ylim(0, 1)
        
        # A√±adir valores en las barras
        for i, precision in enumerate(precisiones):
            axes[0].text(i, precision + 0.02, f'{precision:.3f}', ha='center', fontweight='bold')
        
        # Gr√°fico 2: Matriz de confusi√≥n del mejor modelo
        mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
        y_pred_mejor = resultados[mejor_nombre]['predicciones']
        clases = resultados[mejor_nombre]['modelo'].classes_
        
        cm = confusion_matrix(y_test, y_pred_mejor)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=clases, yticklabels=clases, ax=axes[1])
        axes[1].set_title(f'üéØ Matriz de Confusi√≥n\n{mejor_nombre}', fontweight='bold')
        axes[1].set_xlabel('Predicci√≥n')
        axes[1].set_ylabel('Real')
        
        # Gr√°fico 3: Arquitectura del mejor modelo
        mejor_arq = resultados[mejor_nombre]['arquitectura']
        if isinstance(mejor_arq, int):
            mejor_arq = (mejor_arq,)
        
        capas = [len(variables_disponibles)] + list(mejor_arq) + [len(clases)]
        
        x_pos = np.arange(len(capas))
        axes[2].bar(x_pos, capas, color=['blue', 'green', 'orange', 'red'][:len(capas)])
        axes[2].set_title(f'üèóÔ∏è Arquitectura\n{mejor_nombre}', fontweight='bold')
        axes[2].set_xlabel('Capa')
        axes[2].set_ylabel('Neuronas')
        axes[2].set_xticks(x_pos)
        
        etiquetas = ['Entrada'] + [f'Oculta {i+1}' for i in range(len(mejor_arq))] + ['Salida']
        axes[2].set_xticklabels(etiquetas, rotation=45, ha='right')
        
        # A√±adir valores en las barras
        for i, neurons in enumerate(capas):
            axes[2].text(i, neurons + max(capas)*0.02, str(neurons), ha='center', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('/home/sedc/Proyectos/MineriaDeDatos/results/graficos/redes_neuronas.png', 
                   dpi=150, bbox_inches='tight')
        plt.show()
        
        return True
        
    except Exception as e:
        return False

def guardar_resultados_redes(resultados, variables_disponibles, datos_info):
    """Guardar modelo y reporte de manera optimizada"""
    try:
        import joblib
        
        # Mejor modelo
        mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
        mejor_modelo = resultados[mejor_nombre]['modelo']
        mejor_precision = resultados[mejor_nombre]['precision']
        
        # Guardar modelo
        joblib.dump(mejor_modelo, '/home/sedc/Proyectos/MineriaDeDatos/results/modelos/mejor_red_neuronal.pkl')
        
        # Crear reporte conciso
        reporte = f"""
REPORTE REDES NEURONALES - CLASIFICACI√ìN
=======================================

MEJOR RED: {mejor_nombre}
Descripci√≥n: {resultados[mejor_nombre]['descripcion']}
Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)
Arquitectura: {resultados[mejor_nombre]['arquitectura']}
Activaci√≥n: {resultados[mejor_nombre]['activacion']}
Par√°metros totales: {resultados[mejor_nombre]['n_parametros']:,}

COMPARACI√ìN DE ARQUITECTURAS:
"""
        for nombre, resultado in resultados.items():
            convergencia = resultado['convergencia']
            status = "‚úÖ Convergi√≥" if convergencia['convergio'] else "‚ö†Ô∏è No convergi√≥"
            reporte += f"\n{nombre}:"
            reporte += f"\n  - Precisi√≥n: {resultado['precision']:.3f}"
            reporte += f"\n  - Arquitectura: {resultado['arquitectura']}"
            reporte += f"\n  - Activaci√≥n: {resultado['activacion']}"
            reporte += f"\n  - Par√°metros: {resultado['n_parametros']:,}"
            reporte += f"\n  - Convergencia: {status} ({convergencia['iteraciones']} iter)"
        
        reporte += f"""

DATOS PROCESADOS:
- Registros: {datos_info['n_registros']:,}
- Variables: {len(variables_disponibles)}
- Entrenamiento: {datos_info['n_train']:,}
- Prueba: {datos_info['n_test']:,}

VARIABLES UTILIZADAS:
{', '.join(variables_disponibles)}

CONFIGURACI√ìN:
- Escalado aplicado: StandardScaler
- Solver: lbfgs (optimizaci√≥n limitada)
- Regularizaci√≥n: L2 (alpha)
- Inicializaci√≥n: aleatoria con semilla fija

PRINCIPIO REDES NEURONALES:
- Neuronas artificiales conectadas en capas
- Cada neurona aplica funci√≥n de activaci√≥n
- Aprende patrones complejos no lineales
- Backpropagation para ajustar pesos

VENTAJAS:
- Puede aprender patrones muy complejos
- Vers√°til para diferentes tipos de problemas
- Buena capacidad de generalizaci√≥n

DESVENTAJAS:
- "Caja negra" - dif√≠cil de interpretar
- Requiere ajuste de hiperpar√°metros
- Sensible al overfitting
"""
        
        with open('/home/sedc/Proyectos/MineriaDeDatos/results/reportes/redes_neuronas_reporte.txt', 'w', encoding='utf-8') as f:
            f.write(reporte)
        
        return True
        
    except Exception as e:
        return False

def ejecutar_redes_neuronas():
    """FUNCI√ìN PRINCIPAL - Mantiene compatibilidad con men√∫"""
    print("üß† REDES NEURONALES - CLASIFICACI√ìN")
    print("="*40)
    
    # 1. CARGAR DATOS
    archivo = '/home/sedc/Proyectos/MineriaDeDatos/data/ceros_sin_columnasAB_limpio_weka.csv'
    try:
        datos = pd.read_csv(archivo)
        print(f"‚úÖ Datos cargados: {datos.shape[0]:,} registros")
    except Exception as e:
        print(f"‚ùå Error cargando datos: {e}")
        return
    
    # 2. PREPARAR VARIABLES
    X, y, variables_disponibles = preparar_datos_redes(datos)
    if X is None:
        print("‚ùå No hay suficientes variables para redes neuronales")
        return
    
    print(f"üìä Variables: {len(variables_disponibles)} | Datos limpios: {len(X):,}")
    print(f"üî¢ Neuronas entrada: {len(variables_disponibles)}")
    print(f"üéØ Clases salida: {len(y.unique())}")
    
    # Mostrar distribuci√≥n de categor√≠as
    distribucion = y.value_counts()
    print("üìà Categor√≠as:")
    for categoria, count in distribucion.items():
        print(f"   {categoria}: {count:,} ({count/len(y)*100:.1f}%)")
    
    # 3. DIVIDIR DATOS
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        print(f"üìä Divisi√≥n estratificada: {len(X_train):,} entrenamiento | {len(X_test):,} prueba")
    except ValueError:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        print(f"üìä Divisi√≥n simple: {len(X_train):,} entrenamiento | {len(X_test):,} prueba")
    
    print()
    
    # 4. ENTRENAR REDES NEURONALES
    print("üß† Entrenando redes neuronales...")
    resultados, scaler = entrenar_redes_neuronales(X_train, X_test, y_train, y_test)
    
    if not resultados:
        print("‚ùå No se pudieron entrenar redes neuronales")
        return
    
    # Mostrar resultados
    for nombre, resultado in resultados.items():
        convergencia = resultado['convergencia']
        conv_status = "‚úÖ" if convergencia['convergio'] else "‚ö†Ô∏è"
        print(f"   {nombre:15} ‚Üí Precisi√≥n: {resultado['precision']:.3f} ({resultado['precision']*100:.1f}%) {conv_status}")
    
    # 5. ENCONTRAR MEJOR MODELO
    mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
    mejor_precision = resultados[mejor_nombre]['precision']
    
    print()
    print(f"üèÜ MEJOR RED: {mejor_nombre}")
    print(f"   Descripci√≥n: {resultados[mejor_nombre]['descripcion']}")
    print(f"   Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)")
    print(f"   Arquitectura: {resultados[mejor_nombre]['arquitectura']}")
    print(f"   Par√°metros: {resultados[mejor_nombre]['n_parametros']:,}")
    
    # Informaci√≥n de convergencia
    convergencia_mejor = resultados[mejor_nombre]['convergencia']
    if convergencia_mejor['convergio']:
        print(f"   ‚úÖ Convergi√≥ en {convergencia_mejor['iteraciones']} iteraciones")
    else:
        print(f"   ‚ö†Ô∏è No convergi√≥ completamente ({convergencia_mejor['iteraciones']} iter)")
    
    # 6. AN√ÅLISIS DETALLADO
    y_pred_mejor = resultados[mejor_nombre]['predicciones']
    reporte = classification_report(y_test, y_pred_mejor, output_dict=True)
    
    print("\nüéØ M√©tricas por categor√≠a:")
    for categoria in y.unique():
        if categoria in reporte:
            precision = reporte[categoria]['precision']
            recall = reporte[categoria]['recall']
            f1 = reporte[categoria]['f1-score']
            print(f"   {categoria:12}: Prec={precision:.3f} | Rec={recall:.3f} | F1={f1:.3f}")
    
    # 7. VISUALIZACIONES
    crear_visualizaciones_redes(resultados, y_test, variables_disponibles)
    
    # 8. GUARDAR RESULTADOS
    datos_info = {
        'n_registros': len(X),
        'n_train': len(X_train),
        'n_test': len(X_test)
    }
    
    guardar_resultados_redes(resultados, variables_disponibles, datos_info)
    
    # 9. RESUMEN FINAL
    print()
    print("üìù RESUMEN:")
    print(f"   ‚Ä¢ Mejor arquitectura: {resultados[mejor_nombre]['arquitectura']}")
    print(f"   ‚Ä¢ Funci√≥n activaci√≥n: {resultados[mejor_nombre]['activacion']}")
    print(f"   ‚Ä¢ Precisi√≥n: {mejor_precision*100:.1f}%")
    print(f"   ‚Ä¢ Par√°metros: {resultados[mejor_nombre]['n_parametros']:,}")
    
    if mejor_precision > 0.8:
        print("   üéâ ¬°Excelente aprendizaje neuronal!")
    elif mejor_precision > 0.65:
        print("   üëç Buen aprendizaje de la red neuronal")
    else:
        print("   üîß Aprendizaje moderado")
    
    print("‚úÖ REDES NEURONALES COMPLETADAS")
    return resultados

if __name__ == "__main__":
    ejecutar_redes_neuronas()