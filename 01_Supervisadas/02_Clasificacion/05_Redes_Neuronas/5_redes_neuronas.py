#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
REDES DE NEURONAS - CLASIFICACI√ìN (Versi√≥n Arreglada)
Redes neuronales artificiales para clasificar poblaciones
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

def crear_categorias_poblacion(poblacion):
    """Crear categor√≠as de poblaci√≥n para clasificaci√≥n (umbrales ajustados)"""
    if poblacion <= 500:
        return 'Peque√±a'
    elif poblacion <= 2000:
        return 'Mediana'
    elif poblacion <= 8000:
        return 'Grande'
    else:
        return 'Muy Grande'

def muestreo_estratificado_balanceado(datos, variable_objetivo, n_muestra=3000, min_por_clase=200):
    """Muestreo balanceado para redes neuronales"""
    clases_disponibles = datos[variable_objetivo].value_counts()
    clases_validas = clases_disponibles[clases_disponibles >= min_por_clase]
    
    if len(clases_validas) < 2:
        print(f"‚ö†Ô∏è Solo {len(clases_validas)} clases tienen suficientes muestras")
        return datos.sample(n=min(n_muestra, len(datos)), random_state=42)
    
    # Calcular muestras por clase
    n_clases = len(clases_validas)
    muestras_por_clase = max(min_por_clase, n_muestra // n_clases)
    
    datos_balanceados = []
    for clase in clases_validas.index:
        datos_clase = datos[datos[variable_objetivo] == clase]
        n_tomar = min(muestras_por_clase, len(datos_clase))
        muestra_clase = datos_clase.sample(n=n_tomar, random_state=42)
        datos_balanceados.append(muestra_clase)
    
    return pd.concat(datos_balanceados, ignore_index=True)

def crear_arquitecturas_red():
    """Define diferentes arquitecturas de redes neuronales optimizadas"""
    arquitecturas = {
        'Red Simple': {
            'hidden_layer_sizes': (20,),
            'activation': 'relu',
            'solver': 'adam',
            'alpha': 0.001,
            'max_iter': 300,
            'descripcion': 'Una capa oculta con 20 neuronas'
        },
        'Red Mediana': {
            'hidden_layer_sizes': (30, 15),
            'activation': 'relu',
            'solver': 'adam',
            'alpha': 0.001,
            'max_iter': 400,
            'descripcion': 'Dos capas: 30 y 15 neuronas'
        },
        'Red Profunda': {
            'hidden_layer_sizes': (40, 20, 10),
            'activation': 'relu',
            'solver': 'adam',
            'alpha': 0.001,
            'max_iter': 500,
            'descripcion': 'Tres capas: 40, 20 y 10 neuronas'
        },
        'Red Tanh': {
            'hidden_layer_sizes': (25, 15),
            'activation': 'tanh',
            'solver': 'lbfgs',
            'alpha': 0.01,
            'max_iter': 300,
            'descripcion': 'Activaci√≥n tangente hiperb√≥lica'
        }
    }
    return arquitecturas

def analizar_convergencia(modelo):
    """Analiza la convergencia del entrenamiento"""
    if hasattr(modelo, 'loss_curve_'):
        return {
            'convergi√≥': modelo.n_iter_ < modelo.max_iter,
            'iteraciones': modelo.n_iter_,
            'loss_final': modelo.loss_curve_[-1] if modelo.loss_curve_ else None,
            'loss_curve': modelo.loss_curve_
        }
    return None

def ejecutar_redes_neuronas():
    print("üß† REDES DE NEURONAS - CLASIFICACI√ìN")
    print("="*40)
    print("üìù Objetivo: Clasificar usando redes neuronales artificiales")
    print()
    
    # 1. CARGAR DATOS
    archivo = '/home/sedc/Proyectos/MineriaDeDatos/data/ceros_sin_columnasAB_limpio_weka.csv'
    try:
        datos = pd.read_csv(archivo)
        print(f"‚úÖ Datos cargados: {datos.shape[0]:,} filas, {datos.shape[1]} columnas")
    except Exception as e:
        print(f"‚ùå Error cargando datos: {e}")
        return
    
    # 2. SELECCIONAR VARIABLES PREDICTORAS
    variables_predictoras = [
        'POBFEM', 'POBMAS', 'TOTHOG', 'VIVTOT', 'P_15YMAS', 
        'P_60YMAS', 'GRAPROES', 'PEA', 'POCUPADA'
    ]
    
    variables_disponibles = [v for v in variables_predictoras if v in datos.columns]
    
    if len(variables_disponibles) < 5:
        print("‚ùå No hay suficientes variables para redes neuronales")
        return
    
    print(f"üìä Variables usadas: {', '.join(variables_disponibles)}")
    
    # 3. CREAR CATEGOR√çAS CON UMBRALES AJUSTADOS
    datos['CATEGORIA_POB'] = datos['POBTOT'].apply(crear_categorias_poblacion)
    
    print(f"\nüìà Distribuci√≥n original de categor√≠as:")
    distribucion_original = datos['CATEGORIA_POB'].value_counts()
    for categoria, count in distribucion_original.items():
        print(f"   {categoria:12}: {count:,} ({count/len(datos)*100:.1f}%)")
    
    # 4. MUESTREO ESTRATIFICADO BALANCEADO
    print(f"\nüéØ Aplicando muestreo estratificado balanceado...")
    datos_balanceados = muestreo_estratificado_balanceado(datos, 'CATEGORIA_POB', n_muestra=3000, min_por_clase=200)
    
    print(f"üìù Muestra balanceada: {len(datos_balanceados):,} registros")
    print(f"üìà Nueva distribuci√≥n:")
    for categoria, count in datos_balanceados['CATEGORIA_POB'].value_counts().items():
        print(f"   {categoria:12}: {count:,} ({count/len(datos_balanceados)*100:.1f}%)")
    
    # 5. PREPARAR DATOS FINALES
    datos_limpios = datos_balanceados[variables_disponibles + ['CATEGORIA_POB']].dropna()
    X = datos_limpios[variables_disponibles]
    y = datos_limpios['CATEGORIA_POB']
    
    print(f"\nüßπ Datos finales: {len(datos_limpios):,} registros")
    
    # 6. DIVIDIR DATOS
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        print(f"üìä Divisi√≥n estratificada - Entrenamiento: {len(X_train):,} | Prueba: {len(X_test):,}")
    except Exception as e:
        print(f"‚ö†Ô∏è Error en divisi√≥n estratificada: {e}")
        # Divisi√≥n simple sin estratificaci√≥n
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42
        )
        print(f"üìä Divisi√≥n simple - Entrenamiento: {len(X_train):,} | Prueba: {len(X_test):,}")
    
    # 7. ESCALAR DATOS (CR√çTICO PARA REDES NEURONALES)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"üî¢ Neuronas de entrada: {X_train_scaled.shape[1]}")
    print(f"üéØ Clases de salida: {len(np.unique(y))}")
    print()
    
    # 8. ENTRENAR DIFERENTES ARQUITECTURAS
    arquitecturas = crear_arquitecturas_red()
    
    print("üß† ENTRENANDO REDES NEURONALES...")
    resultados = {}
    
    for nombre, config in arquitecturas.items():
        print(f"   üîÑ Entrenando {nombre}...")
        print(f"      Arquitectura: {config['hidden_layer_sizes']}")
        
        try:
            # Crear configuraci√≥n sin descripci√≥n para el modelo
            config_modelo = {k: v for k, v in config.items() if k != 'descripcion'}
            config_modelo['random_state'] = 42
            config_modelo['early_stopping'] = True
            config_modelo['validation_fraction'] = 0.2
            
            # Crear y entrenar modelo
            modelo = MLPClassifier(**config_modelo)
            modelo.fit(X_train_scaled, y_train)
            
            # Predicciones
            y_pred = modelo.predict(X_test_scaled)
            y_pred_proba = modelo.predict_proba(X_test_scaled)
            
            # M√©tricas
            precision = accuracy_score(y_test, y_pred)
            
            # An√°lisis de convergencia
            convergencia = analizar_convergencia(modelo)
            
            # Calcular n√∫mero de par√°metros aproximado
            n_entrada = X_train_scaled.shape[1]
            capas = config['hidden_layer_sizes']
            n_salida = len(np.unique(y))
            
            n_parametros = n_entrada * capas[0]  # Primera capa
            for i in range(len(capas) - 1):
                n_parametros += capas[i] * capas[i + 1]  # Capas ocultas
            n_parametros += capas[-1] * n_salida  # Capa de salida
            n_parametros += sum(capas) + n_salida  # Bias
            
            resultados[nombre] = {
                'modelo': modelo,
                'precision': precision,
                'predicciones': y_pred,
                'probabilidades': y_pred_proba,
                'arquitectura': config['hidden_layer_sizes'],
                'activacion': config['activation'],
                'solver': config['solver'],
                'descripcion': config['descripcion'],
                'convergencia': convergencia,
                'n_parametros': n_parametros
            }
            
            print(f"   ‚úÖ {nombre} ‚Üí Precisi√≥n: {precision:.3f} ({precision*100:.1f}%)")
            if convergencia:
                print(f"      Iteraciones: {convergencia['iteraciones']}")
                print(f"      Convergi√≥: {'S√≠' if convergencia['convergi√≥'] else 'No'}")
            
        except Exception as e:
            print(f"   ‚ùå Error en {nombre}: {e}")
    
    if not resultados:
        print("‚ùå No se pudo entrenar ninguna red neuronal")
        return
    
    # 9. ENCONTRAR LA MEJOR RED
    mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
    mejor_modelo = resultados[mejor_nombre]['modelo']
    mejor_precision = resultados[mejor_nombre]['precision']
    
    print()
    print(f"üèÜ MEJOR RED: {mejor_nombre}")
    print(f"   Descripci√≥n: {resultados[mejor_nombre]['descripcion']}")
    print(f"   Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)")
    print(f"   Arquitectura: {resultados[mejor_nombre]['arquitectura']}")
    print(f"   Activaci√≥n: {resultados[mejor_nombre]['activacion']}")
    print(f"   Par√°metros: {resultados[mejor_nombre]['n_parametros']:,}")
    
    # 10. AN√ÅLISIS DETALLADO
    print()
    print("üìä AN√ÅLISIS DETALLADO:")
    y_pred_mejor = resultados[mejor_nombre]['predicciones']
    
    # Reporte por clase
    print("\nüéØ M√©tricas por Categor√≠a:")
    try:
        reporte = classification_report(y_test, y_pred_mejor, output_dict=True)
        for categoria in np.unique(y):
            if categoria in reporte:
                precision = reporte[categoria]['precision']
                recall = reporte[categoria]['recall']
                f1 = reporte[categoria]['f1-score']
                support = reporte[categoria]['support']
                print(f"   {categoria:12}: Prec={precision:.3f} | Rec={recall:.3f} | F1={f1:.3f} | N={support}")
    except Exception as e:
        print(f"   ‚ö†Ô∏è Error en reporte: {e}")
    
    # 11. AN√ÅLISIS DE CONVERGENCIA
    print()
    print("üìà AN√ÅLISIS DE CONVERGENCIA:")
    for nombre, resultado in resultados.items():
        convergencia = resultado['convergencia']
        if convergencia:
            status = "‚úÖ Convergi√≥" if convergencia['convergi√≥'] else "‚ö†Ô∏è No convergi√≥"
            print(f"   {nombre:15}: {status} | Iter: {convergencia['iteraciones']}")
    
    # 12. VISUALIZACIONES
    try:
        fig, axes = plt.subplots(3, 3, figsize=(15, 12))
        
        # Gr√°fico 1: Comparaci√≥n de precisi√≥n
        axes[0,0].bar(range(len(resultados)), 
                     [resultados[m]['precision'] for m in resultados.keys()],
                     color=['lightblue', 'lightgreen', 'orange', 'pink'][:len(resultados)])
        axes[0,0].set_title('üß† Precisi√≥n por Arquitectura', fontweight='bold')
        axes[0,0].set_ylabel('Precisi√≥n')
        axes[0,0].set_xticks(range(len(resultados)))
        axes[0,0].set_xticklabels([n.split()[1] for n in resultados.keys()], rotation=45)
        
        # A√±adir valores en las barras
        for i, (nombre, resultado) in enumerate(resultados.items()):
            axes[0,0].text(i, resultado['precision'] + 0.01, f"{resultado['precision']:.3f}", 
                          ha='center', fontweight='bold')
        
        # Gr√°fico 2: Matriz de confusi√≥n
        try:
            cm = confusion_matrix(y_test, y_pred_mejor)
            clases = np.unique(y)
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                       xticklabels=clases, yticklabels=clases, ax=axes[0,1])
            axes[0,1].set_title(f'üéØ Matriz de Confusi√≥n\n{mejor_nombre}', fontweight='bold')
            axes[0,1].set_xlabel('Predicci√≥n')
            axes[0,1].set_ylabel('Real')
        except:
            axes[0,1].text(0.5, 0.5, 'Matriz no\ndisponible', ha='center', va='center')
            axes[0,1].set_title('üéØ Matriz de Confusi√≥n', fontweight='bold')
        
        # Gr√°fico 3: Curvas de p√©rdida
        mejor_convergencia = resultados[mejor_nombre]['convergencia']
        if mejor_convergencia and mejor_convergencia['loss_curve']:
            axes[0,2].plot(mejor_convergencia['loss_curve'], 'b-', linewidth=2)
            axes[0,2].set_title(f'üìâ Curva de P√©rdida\n{mejor_nombre}', fontweight='bold')
            axes[0,2].set_xlabel('√âpoca')
            axes[0,2].set_ylabel('P√©rdida')
            axes[0,2].grid(True, alpha=0.3)
        else:
            axes[0,2].text(0.5, 0.5, 'Curva de p√©rdida\nno disponible', ha='center', va='center')
            axes[0,2].set_title('üìâ Curva de P√©rdida', fontweight='bold')
        
        # Gr√°fico 4: N√∫mero de par√°metros vs precisi√≥n
        n_params = [resultados[m]['n_parametros'] for m in resultados.keys()]
        precisiones = [resultados[m]['precision'] for m in resultados.keys()]
        axes[1,0].scatter(n_params, precisiones, s=100, alpha=0.7, c=['red', 'green', 'blue', 'orange'][:len(n_params)])
        for i, nombre in enumerate(resultados.keys()):
            axes[1,0].annotate(nombre.split()[1][:6], (n_params[i], precisiones[i]), 
                              xytext=(5, 5), textcoords='offset points', fontsize=8)
        axes[1,0].set_xlabel('N√∫mero de Par√°metros')
        axes[1,0].set_ylabel('Precisi√≥n')
        axes[1,0].set_title('‚öñÔ∏è Complejidad vs Precisi√≥n', fontweight='bold')
        
        # Gr√°fico 5: Distribuci√≥n de confianza
        probabilidades = resultados[mejor_nombre]['probabilidades']
        max_probs = np.max(probabilidades, axis=1)
        axes[1,1].hist(max_probs, bins=15, alpha=0.7, color='purple', edgecolor='black')
        axes[1,1].set_title('üìà Confianza de Predicciones', fontweight='bold')
        axes[1,1].set_xlabel('Confianza M√°xima')
        axes[1,1].set_ylabel('Frecuencia')
        
        # Gr√°fico 6: Iteraciones hasta convergencia
        iteraciones = []
        nombres_conv = []
        for nombre, resultado in resultados.items():
            if resultado['convergencia']:
                iteraciones.append(resultado['convergencia']['iteraciones'])
                nombres_conv.append(nombre.split()[1])
        
        if iteraciones:
            axes[1,2].bar(nombres_conv, iteraciones, color='cyan')
            axes[1,2].set_title('‚è±Ô∏è Iteraciones para Convergencia', fontweight='bold')
            axes[1,2].set_ylabel('Iteraciones')
            axes[1,2].tick_params(axis='x', rotation=45)
        
        # Gr√°fico 7: Arquitectura de la mejor red
        mejor_arq = resultados[mejor_nombre]['arquitectura']
        capas = [X_train_scaled.shape[1]] + list(mejor_arq) + [len(np.unique(y))]
        
        x_pos = np.arange(len(capas))
        axes[2,0].bar(x_pos, capas, color=['blue', 'green', 'orange', 'red', 'purple'][:len(capas)])
        axes[2,0].set_title(f'üèóÔ∏è Arquitectura Mejor Red\n{mejor_nombre}', fontweight='bold')
        axes[2,0].set_xlabel('Capa')
        axes[2,0].set_ylabel('Neuronas')
        axes[2,0].set_xticks(x_pos)
        axes[2,0].set_xticklabels(['Entrada'] + [f'Oculta {i+1}' for i in range(len(mejor_arq))] + ['Salida'])
        
        for i, neurons in enumerate(capas):
            axes[2,0].text(i, neurons + max(capas)*0.02, str(neurons), ha='center', fontweight='bold')
        
        # Gr√°fico 8: Distribuci√≥n de categor√≠as
        axes[2,1].pie(datos_balanceados['CATEGORIA_POB'].value_counts().values,
                     labels=datos_balanceados['CATEGORIA_POB'].value_counts().index,
                     autopct='%1.1f%%', startangle=90)
        axes[2,1].set_title('üìä Distribuci√≥n Final', fontweight='bold')
        
        # Gr√°fico 9: Curvas de p√©rdida comparativas
        for nombre, resultado in resultados.items():
            if resultado['convergencia'] and resultado['convergencia']['loss_curve']:
                loss_curve = resultado['convergencia']['loss_curve']
                axes[2,2].plot(loss_curve, label=nombre.split()[1], alpha=0.7, linewidth=2)
        
        axes[2,2].set_title('üìâ Curvas de P√©rdida Comparativas', fontweight='bold')
        axes[2,2].set_xlabel('√âpoca')
        axes[2,2].set_ylabel('P√©rdida')
        axes[2,2].legend()
        axes[2,2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('/home/sedc/Proyectos/MineriaDeDatos/results/graficos/redes_neuronas_clasificacion.png', 
                   dpi=150, bbox_inches='tight')
        plt.show()
        
        print("üíæ Gr√°ficos guardados: results/graficos/redes_neuronas_clasificacion.png")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error en visualizaciones: {e}")
    
    # 13. GUARDAR RESULTADOS
    try:
        import joblib
        
        # Guardar el mejor modelo y el scaler
        joblib.dump(mejor_modelo, '/home/sedc/Proyectos/MineriaDeDatos/results/modelos/mejor_red_neuronal.pkl')
        joblib.dump(scaler, '/home/sedc/Proyectos/MineriaDeDatos/results/modelos/scaler_red_neuronal.pkl')
        
        # Crear reporte detallado
        reporte_completo = f"""
REPORTE REDES NEURONALES - CLASIFICACI√ìN
=======================================

MEJOR RED: {mejor_nombre}
Descripci√≥n: {resultados[mejor_nombre]['descripcion']}
Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)
Arquitectura: {resultados[mejor_nombre]['arquitectura']}
Activaci√≥n: {resultados[mejor_nombre]['activacion']}
Solver: {resultados[mejor_nombre]['solver']}
Par√°metros totales: {resultados[mejor_nombre]['n_parametros']:,}

CONVERGENCIA:
"""
        conv_mejor = resultados[mejor_nombre]['convergencia']
        if conv_mejor:
            reporte_completo += f"- Convergi√≥: {'S√≠' if conv_mejor['convergi√≥'] else 'No'}\n"
            reporte_completo += f"- Iteraciones: {conv_mejor['iteraciones']}\n"
            reporte_completo += f"- P√©rdida final: {conv_mejor['loss_final']:.6f}\n"
        
        reporte_completo += f"""

COMPARACI√ìN DE ARQUITECTURAS:
"""
        for nombre, resultado in resultados.items():
            reporte_completo += f"\n{nombre}:"
            reporte_completo += f"\n  - Precisi√≥n: {resultado['precision']:.3f}"
            reporte_completo += f"\n  - Arquitectura: {resultado['arquitectura']}"
            reporte_completo += f"\n  - Activaci√≥n: {resultado['activacion']}"
            reporte_completo += f"\n  - Par√°metros: {resultado['n_parametros']:,}"
            if resultado['convergencia']:
                reporte_completo += f"\n  - Iteraciones: {resultado['convergencia']['iteraciones']}"
        
        reporte_completo += f"""

VARIABLES UTILIZADAS:
{', '.join(variables_disponibles)}

CONFIGURACI√ìN:
- Neuronas de entrada: {X_train_scaled.shape[1]}
- Clases de salida: {len(np.unique(y))}
- Datos de entrenamiento: {len(X_train):,}
- Datos de prueba: {len(X_test):,}

DATOS PROCESADOS:
- Registros originales: {len(datos):,}
- Muestra balanceada: {len(datos_balanceados):,}
- Muestreo estratificado aplicado

NOTAS:
- Se aplic√≥ escalado est√°ndar a todas las variables
- Se utiliz√≥ early stopping para evitar overfitting
- Se reserv√≥ 20% de datos de entrenamiento para validaci√≥n
- Umbrales ajustados para mejor distribuci√≥n de clases
"""
        
        with open('/home/sedc/Proyectos/MineriaDeDatos/results/reportes/redes_neuronas_reporte.txt', 'w', encoding='utf-8') as f:
            f.write(reporte_completo)
        
        print("üíæ Modelo guardado: results/modelos/mejor_red_neuronal.pkl")
        print("üíæ Scaler guardado: results/modelos/scaler_red_neuronal.pkl")
        print("üìÑ Reporte guardado: results/reportes/redes_neuronas_reporte.txt")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error guardando archivos: {e}")
    
    # 14. RESUMEN FINAL
    print()
    print("üìù RESUMEN REDES NEURONALES:")
    print(f"   ‚Ä¢ Mejor arquitectura: {resultados[mejor_nombre]['arquitectura']}")
    print(f"   ‚Ä¢ Funci√≥n activaci√≥n: {resultados[mejor_nombre]['activacion']}")
    print(f"   ‚Ä¢ Precisi√≥n alcanzada: {mejor_precision*100:.1f}%")
    print(f"   ‚Ä¢ Par√°metros totales: {resultados[mejor_nombre]['n_parametros']:,}")
    
    if conv_mejor:
        if conv_mejor['convergi√≥']:
            print(f"   ‚Ä¢ Red convergi√≥ en {conv_mejor['iteraciones']} iteraciones ‚úÖ")
        else:
            print(f"   ‚Ä¢ Red no convergi√≥ completamente ‚ö†Ô∏è")
    
    if mejor_precision > 0.8:
        print("   ‚Ä¢ ¬°Excelente aprendizaje neuronal! üß†üéâ")
    elif mejor_precision > 0.65:
        print("   ‚Ä¢ Buen aprendizaje de la red neuronal üëç")
    else:
        print("   ‚Ä¢ Aprendizaje moderado, considerar ajustes üîß")
    
    print("   ‚Ä¢ Ventaja: Puede aprender patrones complejos no lineales")
    print("   ‚Ä¢ Desventaja: Caja negra, dif√≠cil de interpretar")
    
    print("‚úÖ REDES NEURONALES COMPLETADAS")
    return resultados

if __name__ == "__main__":
    ejecutar_redes_neuronas()