

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

def crear_categorias_poblacion(poblacion):
    """Crear categor√≠as de poblaci√≥n para clasificaci√≥n"""
    if poblacion <= 1000:
        return 'Peque√±a'
    elif poblacion <= 5000:
        return 'Mediana'
    elif poblacion <= 20000:
        return 'Grande'
    else:
        return 'Muy Grande'

def ejecutar_arboles_decision():
    print("üå≥ √ÅRBOLES DE DECISI√ìN - CLASIFICACI√ìN")
    print("="*40)
    print("üìù Objetivo: Clasificar comunidades por tama√±o de poblaci√≥n")
    print()
    
    # 1. CARGAR DATOS
    archivo = '/home/sedc/Proyectos/MineriaDeDatos/data/ceros_sin_columnasAB_limpio_weka.csv'
    try:
        datos = pd.read_csv(archivo)
        print(f"‚úÖ Datos cargados: {datos.shape[0]:,} filas, {datos.shape[1]} columnas")
    except Exception as e:
        print(f"‚ùå Error cargando datos: {e}")
        return
    
    # 2. SELECCIONAR VARIABLES PREDICTORAS
    variables_predictoras = [
        'POBFEM', 'POBMAS', 'TOTHOG', 'VIVTOT', 'P_15YMAS', 
        'P_60YMAS', 'GRAPROES', 'PEA', 'POCUPADA'
    ]
    
    # Verificar qu√© variables est√°n disponibles
    variables_disponibles = [v for v in variables_predictoras if v in datos.columns]
    
    if len(variables_disponibles) < 3:
        print("‚ùå No hay suficientes variables para clasificaci√≥n")
        return
    
    print(f"üìä Variables usadas: {', '.join(variables_disponibles)}")
    
    # 3. CREAR VARIABLE OBJETIVO (CLASIFICACI√ìN)
    datos['CATEGORIA_POB'] = datos['POBTOT'].apply(crear_categorias_poblacion)
    
    # 4. PREPARAR DATOS
    datos_limpios = datos[variables_disponibles + ['CATEGORIA_POB']].dropna()
    X = datos_limpios[variables_disponibles]
    y = datos_limpios['CATEGORIA_POB']
    
    print(f"üßπ Datos limpios: {len(datos_limpios):,} registros")
    print(f"üìà Distribuci√≥n de categor√≠as:")
    for categoria, count in y.value_counts().items():
        print(f"   {categoria:12}: {count:,} ({count/len(y)*100:.1f}%)")
    
    # 5. DIVIDIR DATOS
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"üìä Entrenamiento: {len(X_train):,} | Prueba: {len(X_test):,}")
    print()
    
    # 6. ENTRENAR DIFERENTES CONFIGURACIONES DE √ÅRBOLES
    configuraciones = {
        '√Årbol Simple': {
            'max_depth': 3,
            'min_samples_split': 100,
            'min_samples_leaf': 50
        },
        '√Årbol Balanceado': {
            'max_depth': 5,
            'min_samples_split': 50,
            'min_samples_leaf': 20
        },
        '√Årbol Profundo': {
            'max_depth': 10,
            'min_samples_split': 20,
            'min_samples_leaf': 10
        }
    }
    
    print("üå± ENTRENANDO √ÅRBOLES DE DECISI√ìN...")
    resultados = {}
    
    for nombre, params in configuraciones.items():
        print(f"   üîÑ Entrenando {nombre}...")
        
        # Crear y entrenar modelo
        modelo = DecisionTreeClassifier(
            **params,
            random_state=42,
            class_weight='balanced'  # Para balancear clases
        )
        
        modelo.fit(X_train, y_train)
        
        # Predicciones
        y_pred = modelo.predict(X_test)
        
        # M√©tricas
        precision = accuracy_score(y_test, y_pred)
        
        resultados[nombre] = {
            'modelo': modelo,
            'precision': precision,
            'predicciones': y_pred,
            'profundidad': modelo.get_depth(),
            'n_hojas': modelo.get_n_leaves()
        }
        
        print(f"   ‚úÖ {nombre} ‚Üí Precisi√≥n: {precision:.3f} ({precision*100:.1f}%)")
        print(f"      Profundidad: {modelo.get_depth()} | Hojas: {modelo.get_n_leaves()}")
    
    # 7. ENCONTRAR EL MEJOR MODELO
    mejor_nombre = max(resultados.keys(), key=lambda x: resultados[x]['precision'])
    mejor_modelo = resultados[mejor_nombre]['modelo']
    mejor_precision = resultados[mejor_nombre]['precision']
    
    print()
    print(f"üèÜ MEJOR MODELO: {mejor_nombre}")
    print(f"   Precisi√≥n: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)")
    
    # 8. REPORTE DETALLADO DEL MEJOR MODELO
    print()
    print("üìä REPORTE DETALLADO:")
    y_pred_mejor = resultados[mejor_nombre]['predicciones']
    
    print("\nüéØ Precisi√≥n por Categor√≠a:")
    reporte = classification_report(y_test, y_pred_mejor, output_dict=True)
    for categoria in ['Peque√±a', 'Mediana', 'Grande', 'Muy Grande']:
        if categoria in reporte:
            precision = reporte[categoria]['precision']
            recall = reporte[categoria]['recall']
            f1 = reporte[categoria]['f1-score']
            print(f"   {categoria:12}: Prec={precision:.3f} | Rec={recall:.3f} | F1={f1:.3f}")
    
    # 9. IMPORTANCIA DE VARIABLES
    print()
    print("üìà IMPORTANCIA DE VARIABLES:")
    importancias = mejor_modelo.feature_importances_
    variables_importancia = list(zip(variables_disponibles, importancias))
    variables_importancia.sort(key=lambda x: x[1], reverse=True)
    
    for i, (variable, importancia) in enumerate(variables_importancia):
        barras = '‚ñà' * int(importancia * 30)
        print(f"   {i+1}. {variable:12} {barras} {importancia:.3f}")
    
    # 10. VISUALIZACIONES
    try:
        # Crear figura con m√∫ltiples gr√°ficos
        fig = plt.figure(figsize=(20, 12))
        
        # Gr√°fico 1: √Årbol de decisi√≥n
        plt.subplot(2, 3, 1)
        plot_tree(mejor_modelo, 
                 feature_names=variables_disponibles,
                 class_names=mejor_modelo.classes_,
                 filled=True,
                 rounded=True,
                 fontsize=8,
                 max_depth=3)  # Limitar profundidad para visualizaci√≥n
        plt.title(f'üå≥ {mejor_nombre}\n(Primeros 3 niveles)', fontweight='bold')
        
        # Gr√°fico 2: Matriz de confusi√≥n
        plt.subplot(2, 3, 2)
        cm = confusion_matrix(y_test, y_pred_mejor)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=mejor_modelo.classes_,
                   yticklabels=mejor_modelo.classes_)
        plt.title('üéØ Matriz de Confusi√≥n', fontweight='bold')
        plt.xlabel('Predicci√≥n')
        plt.ylabel('Real')
        
        # Gr√°fico 3: Comparaci√≥n de precisi√≥n
        plt.subplot(2, 3, 3)
        nombres = list(resultados.keys())
        precisiones = [resultados[m]['precision'] for m in nombres]
        colores = ['lightgreen', 'orange', 'lightcoral']
        
        barras = plt.bar(range(len(nombres)), precisiones, color=colores)
        plt.title('üìä Precisi√≥n por Configuraci√≥n', fontweight='bold')
        plt.ylabel('Precisi√≥n')
        plt.xticks(range(len(nombres)), nombres, rotation=45, ha='right')
        plt.ylim(0, 1)
        
        for i, (barra, precision) in enumerate(zip(barras, precisiones)):
            plt.text(i, precision + 0.02, f'{precision:.3f}', 
                    ha='center', fontweight='bold')
        
        # Gr√°fico 4: Importancia de variables
        plt.subplot(2, 3, 4)
        variables_top = [v[0] for v in variables_importancia[:6]]
        importancias_top = [v[1] for v in variables_importancia[:6]]
        plt.barh(range(len(variables_top)), importancias_top, color='purple')
        plt.yticks(range(len(variables_top)), variables_top)
        plt.xlabel('Importancia')
        plt.title('üìà Top 6 Variables Importantes', fontweight='bold')
        
        # Gr√°fico 5: Distribuci√≥n de profundidades
        plt.subplot(2, 3, 5)
        nombres_cortos = [n.split()[1] for n in nombres]
        profundidades = [resultados[m]['profundidad'] for m in nombres]
        plt.bar(range(len(nombres_cortos)), profundidades, color='cyan')
        plt.title('üå≥ Profundidad por Modelo', fontweight='bold')
        plt.ylabel('Niveles')
        plt.xticks(range(len(nombres_cortos)), nombres_cortos)
        
        # Gr√°fico 6: N√∫mero de hojas
        plt.subplot(2, 3, 6)
        n_hojas = [resultados[m]['n_hojas'] for m in nombres]
        plt.bar(range(len(nombres_cortos)), n_hojas, color='gold')
        plt.title('üçÉ N√∫mero de Decisiones Finales', fontweight='bold')
        plt.ylabel('Hojas')
        plt.xticks(range(len(nombres_cortos)), nombres_cortos)
        
        plt.tight_layout()
        plt.savefig('/home/sedc/Proyectos/MineriaDeDatos/results/graficos/arboles_decision_clasificacion.png', 
                   dpi=150, bbox_inches='tight')
        plt.show()
        
        print("üíæ Gr√°ficos guardados en: results/graficos/arboles_decision_clasificacion.png")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error creando visualizaciones: {e}")
    
    # 11. GUARDAR MODELO Y RESULTADOS
    try:
        import joblib
        
        # Guardar el mejor modelo
        joblib.dump(mejor_modelo, '/home/sedc/Proyectos/MineriaDeDatos/results/modelos/mejor_arbol_decision.pkl')
        
        # Guardar reporte
        reporte_texto = f"""
REPORTE √ÅRBOLES DE DECISI√ìN - CLASIFICACI√ìN
==========================================

MEJOR MODELO: {mejor_nombre}
Precisi√≥n General: {mejor_precision:.3f} ({mejor_precision*100:.1f}%)
Profundidad: {resultados[mejor_nombre]['profundidad']} niveles
Decisiones Finales: {resultados[mejor_nombre]['n_hojas']} hojas

VARIABLES M√ÅS IMPORTANTES:
{chr(10).join([f"{i+1}. {var}: {imp:.3f}" for i, (var, imp) in enumerate(variables_importancia[:5])])}

DATOS UTILIZADOS:
- Total registros: {len(datos_limpios):,}
- Variables predictoras: {len(variables_disponibles)}
- Categor√≠as: {len(mejor_modelo.classes_)}
"""
        
        with open('/home/sedc/Proyectos/MineriaDeDatos/results/reportes/arboles_decision_reporte.txt', 'w', encoding='utf-8') as f:
            f.write(reporte_texto)
        
        print("üíæ Modelo guardado en: results/modelos/mejor_arbol_decision.pkl")
        print("üìÑ Reporte guardado en: results/reportes/arboles_decision_reporte.txt")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error guardando archivos: {e}")
    
    # 12. RESUMEN FINAL
    print()
    print("üìù RESUMEN:")
    print(f"   ‚Ä¢ Mejor configuraci√≥n: {mejor_nombre}")
    print(f"   ‚Ä¢ Precisi√≥n alcanzada: {mejor_precision*100:.1f}%")
    
    if mejor_precision > 0.8:
        print("   ‚Ä¢ ¬°Excelente clasificaci√≥n! üéâ")
    elif mejor_precision > 0.6:
        print("   ‚Ä¢ Buena clasificaci√≥n üëç")
    else:
        print("   ‚Ä¢ Clasificaci√≥n moderada, revisar datos üîß")
    
    print("‚úÖ √ÅRBOLES DE DECISI√ìN COMPLETADOS")
    return resultados

if __name__ == "__main__":
    ejecutar_arboles_decision()