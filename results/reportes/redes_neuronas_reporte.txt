
REPORTE REDES NEURONALES - CLASIFICACIÓN
=======================================

MEJOR RED: Red Tanh
Descripción: Activación tangente hiperbólica
Precisión: 0.997 (99.7%)
Arquitectura: (25,)
Activación: tanh
Parámetros totales: 354

COMPARACIÓN DE ARQUITECTURAS:

Red Simple:
  - Precisión: 0.996
  - Arquitectura: (20,)
  - Activación: relu
  - Parámetros: 284
  - Convergencia: ⚠️ No convergió (500 iter)
Red Profunda:
  - Precisión: 0.997
  - Arquitectura: (30, 15)
  - Activación: relu
  - Parámetros: 829
  - Convergencia: ⚠️ No convergió (600 iter)
Red Tanh:
  - Precisión: 0.997
  - Arquitectura: (25,)
  - Activación: tanh
  - Parámetros: 354
  - Convergencia: ⚠️ No convergió (400 iter)

DATOS PROCESADOS:
- Registros: 5,000
- Variables: 9
- Entrenamiento: 3,500
- Prueba: 1,500

VARIABLES UTILIZADAS:
POBFEM, POBMAS, TOTHOG, VIVTOT, P_15YMAS, P_60YMAS, GRAPROES, PEA, POCUPADA

CONFIGURACIÓN:
- Escalado aplicado: StandardScaler
- Solver: lbfgs (optimización limitada)
- Regularización: L2 (alpha)
- Inicialización: aleatoria con semilla fija

PRINCIPIO REDES NEURONALES:
- Neuronas artificiales conectadas en capas
- Cada neurona aplica función de activación
- Aprende patrones complejos no lineales
- Backpropagation para ajustar pesos

VENTAJAS:
- Puede aprender patrones muy complejos
- Versátil para diferentes tipos de problemas
- Buena capacidad de generalización

DESVENTAJAS:
- "Caja negra" - difícil de interpretar
- Requiere ajuste de hiperparámetros
- Sensible al overfitting
