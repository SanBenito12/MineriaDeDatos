
REPORTE CLASIFICACIÓN K-NN (BASADA EN EJEMPLARES)
===============================================

MEJOR MODELO: K-NN Óptimo (K=15)
Precisión: 0.961 (96.1%)
K Óptimo encontrado: 15
K utilizado: 15
Ponderación: distance

COMPARACIÓN DE CONFIGURACIONES:

K-NN Óptimo (K=15):
  - Precisión: 0.961
  - K: 15
  - Weights: distance
K-NN Clásico (K=5):
  - Precisión: 0.959
  - K: 5
  - Weights: uniform
K-NN Ponderado (K=7):
  - Precisión: 0.959
  - K: 7
  - Weights: distance

DATOS PROCESADOS:
- Registros: 40,000
- Variables: 9
- Entrenamiento: 28,000
- Prueba: 12,000

VARIABLES UTILIZADAS:
POBFEM, POBMAS, TOTHOG, VIVTOT, P_15YMAS, P_60YMAS, GRAPROES, PEA, POCUPADA

PRINCIPIO K-NN:
- Clasifica según la mayoría de los K vecinos más cercanos
- No requiere entrenamiento (lazy learning)
- Sensible a la escala (por eso se aplica StandardScaler)
- Computacionalmente costoso para predicción

CONFIGURACIÓN:
- Métrica de distancia: Euclidiana
- Escalado aplicado: StandardScaler
- Validación cruzada: 5-fold para K óptimo
